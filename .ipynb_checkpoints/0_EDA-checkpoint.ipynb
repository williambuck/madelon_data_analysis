{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3 - Madelon Data Analysis\n",
    "## Step 0: EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!conda install psycopg2 --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import psycopg2 as pg2\n",
    "from psycopg2.extras import RealDictCursor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, LogisticRegression, LassoCV, ElasticNetCV\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, \\\n",
    "                                      SelectFromModel, \\\n",
    "                                      RFE, SelectPercentile, \\\n",
    "                                      f_regression\n",
    "\n",
    "from IPython.display import display\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructor Provided Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def con_cur_to_class_db():\n",
    "    '''This function will return a connection and cursor object from the Madelon data that was provided by the\n",
    "    instructors. It is not the downloaded version of the data from the UCI website.'''\n",
    "    \n",
    "    con = pg2.connect(host='34.211.227.227',\n",
    "                  dbname='postgres',\n",
    "                  user='postgres')\n",
    "    cur = con.cursor(cursor_factory=RealDictCursor)\n",
    "    \n",
    "    return con, cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "con, cur = con_cur_to_class_db()\n",
    "cur.execute('SELECT * FROM madelon LIMIT 2;')\n",
    "results = cur.fetchall()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>feat_000</th>\n",
       "      <th>feat_001</th>\n",
       "      <th>feat_002</th>\n",
       "      <th>feat_003</th>\n",
       "      <th>feat_004</th>\n",
       "      <th>feat_005</th>\n",
       "      <th>feat_006</th>\n",
       "      <th>feat_007</th>\n",
       "      <th>feat_008</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_991</th>\n",
       "      <th>feat_992</th>\n",
       "      <th>feat_993</th>\n",
       "      <th>feat_994</th>\n",
       "      <th>feat_995</th>\n",
       "      <th>feat_996</th>\n",
       "      <th>feat_997</th>\n",
       "      <th>feat_998</th>\n",
       "      <th>feat_999</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52016</td>\n",
       "      <td>-2.144283</td>\n",
       "      <td>-0.64021</td>\n",
       "      <td>-1.295197</td>\n",
       "      <td>-0.153244</td>\n",
       "      <td>-0.139236</td>\n",
       "      <td>-0.979140</td>\n",
       "      <td>0.626234</td>\n",
       "      <td>0.145955</td>\n",
       "      <td>0.280069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.324557</td>\n",
       "      <td>-0.788472</td>\n",
       "      <td>-0.207519</td>\n",
       "      <td>1.484341</td>\n",
       "      <td>-0.561046</td>\n",
       "      <td>-1.462825</td>\n",
       "      <td>0.306762</td>\n",
       "      <td>0.121219</td>\n",
       "      <td>1.033784</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52017</td>\n",
       "      <td>0.215722</td>\n",
       "      <td>1.92297</td>\n",
       "      <td>0.331445</td>\n",
       "      <td>-0.961705</td>\n",
       "      <td>0.204086</td>\n",
       "      <td>2.317454</td>\n",
       "      <td>-0.667207</td>\n",
       "      <td>0.259223</td>\n",
       "      <td>0.605462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090224</td>\n",
       "      <td>0.654281</td>\n",
       "      <td>2.158872</td>\n",
       "      <td>-1.060857</td>\n",
       "      <td>-1.032985</td>\n",
       "      <td>-1.304050</td>\n",
       "      <td>-0.476265</td>\n",
       "      <td>1.988284</td>\n",
       "      <td>1.934122</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 1002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     _id  feat_000  feat_001  feat_002  feat_003  feat_004  feat_005  \\\n",
       "0  52016 -2.144283  -0.64021 -1.295197 -0.153244 -0.139236 -0.979140   \n",
       "1  52017  0.215722   1.92297  0.331445 -0.961705  0.204086  2.317454   \n",
       "\n",
       "   feat_006  feat_007  feat_008   ...    feat_991  feat_992  feat_993  \\\n",
       "0  0.626234  0.145955  0.280069   ...    0.324557 -0.788472 -0.207519   \n",
       "1 -0.667207  0.259223  0.605462   ...    0.090224  0.654281  2.158872   \n",
       "\n",
       "   feat_994  feat_995  feat_996  feat_997  feat_998  feat_999  target  \n",
       "0  1.484341 -0.561046 -1.462825  0.306762  0.121219  1.033784       1  \n",
       "1 -1.060857 -1.032985 -1.304050 -0.476265  1.988284  1.934122       0  \n",
       "\n",
       "[2 rows x 1002 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UCI Web Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assigning file paths to variables. \n",
    "\n",
    "train_data_uci_madelon = './web_madelon_data/madelon_train.data.txt'\n",
    "train_label_uci_madelon = './web_madelon_data/madelon_train.labels.txt'\n",
    "\n",
    "val_data_uci_madelon = './web_madelon_data/madelon_valid.data.txt'\n",
    "val_label_uci_madelon = './web_madelon_data/madelon_valid.labels.txt'\n",
    "\n",
    "test_data_uci_madelon = './web_madelon_data/madelon_test.data.txt'\n",
    "\n",
    "params_uci_madelon = './web_madelon_data/madelon.param.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating dataframes for the train, test, and val datasets.\n",
    "\n",
    "train_uci_df = pd.read_csv(train_data_uci_madelon, delimiter=' ', header=None).drop(500, axis=1)\n",
    "test_uci_df = pd.read_csv(test_data_uci_madelon, delimiter=' ', header=None).drop(500, axis=1)\n",
    "val_uci_df = pd.read_csv(val_data_uci_madelon, delimiter=' ', header=None).drop(500, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4400\n",
      "600\n",
      "2000\n",
      "1800\n"
     ]
    }
   ],
   "source": [
    "# Checking to make sure I have the right amount of rows.\n",
    "\n",
    "print(len(val_uci_df) + len(train_uci_df) + len(test_uci_df))\n",
    "print(len(val_uci_df))\n",
    "print(len(train_uci_df))\n",
    "print(len(test_uci_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating column names for all of the uci dataframes.\n",
    "\n",
    "feature_col_names = ['feat_{}'.format(i) for i in range(0,500)]\n",
    "\n",
    "train_uci_df.columns = feature_col_names\n",
    "test_uci_df.columns = feature_col_names\n",
    "val_uci_df.columns = feature_col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = pd.read_csv(train_label_uci_madelon, header=None)\n",
    "y_val = pd.read_csv(val_label_uci_madelon, header=None)\n",
    "\n",
    "y_train.columns = ['target']\n",
    "y_val.columns = ['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_uci_df = pd.merge(train_uci_df, y_train, left_index=True, right_index=True)\n",
    "val_uci_df = pd.merge(val_uci_df, y_val, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_0</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_491</th>\n",
       "      <th>feat_492</th>\n",
       "      <th>feat_493</th>\n",
       "      <th>feat_494</th>\n",
       "      <th>feat_495</th>\n",
       "      <th>feat_496</th>\n",
       "      <th>feat_497</th>\n",
       "      <th>feat_498</th>\n",
       "      <th>feat_499</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>485</td>\n",
       "      <td>477</td>\n",
       "      <td>537</td>\n",
       "      <td>479</td>\n",
       "      <td>452</td>\n",
       "      <td>471</td>\n",
       "      <td>491</td>\n",
       "      <td>476</td>\n",
       "      <td>475</td>\n",
       "      <td>473</td>\n",
       "      <td>...</td>\n",
       "      <td>481</td>\n",
       "      <td>477</td>\n",
       "      <td>485</td>\n",
       "      <td>511</td>\n",
       "      <td>485</td>\n",
       "      <td>481</td>\n",
       "      <td>479</td>\n",
       "      <td>475</td>\n",
       "      <td>496</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>483</td>\n",
       "      <td>458</td>\n",
       "      <td>460</td>\n",
       "      <td>487</td>\n",
       "      <td>587</td>\n",
       "      <td>475</td>\n",
       "      <td>526</td>\n",
       "      <td>479</td>\n",
       "      <td>485</td>\n",
       "      <td>469</td>\n",
       "      <td>...</td>\n",
       "      <td>478</td>\n",
       "      <td>487</td>\n",
       "      <td>338</td>\n",
       "      <td>513</td>\n",
       "      <td>486</td>\n",
       "      <td>483</td>\n",
       "      <td>492</td>\n",
       "      <td>510</td>\n",
       "      <td>517</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>487</td>\n",
       "      <td>542</td>\n",
       "      <td>499</td>\n",
       "      <td>468</td>\n",
       "      <td>448</td>\n",
       "      <td>471</td>\n",
       "      <td>442</td>\n",
       "      <td>478</td>\n",
       "      <td>480</td>\n",
       "      <td>477</td>\n",
       "      <td>...</td>\n",
       "      <td>481</td>\n",
       "      <td>492</td>\n",
       "      <td>650</td>\n",
       "      <td>506</td>\n",
       "      <td>501</td>\n",
       "      <td>480</td>\n",
       "      <td>489</td>\n",
       "      <td>499</td>\n",
       "      <td>498</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>480</td>\n",
       "      <td>491</td>\n",
       "      <td>510</td>\n",
       "      <td>485</td>\n",
       "      <td>495</td>\n",
       "      <td>472</td>\n",
       "      <td>417</td>\n",
       "      <td>474</td>\n",
       "      <td>502</td>\n",
       "      <td>476</td>\n",
       "      <td>...</td>\n",
       "      <td>480</td>\n",
       "      <td>474</td>\n",
       "      <td>572</td>\n",
       "      <td>454</td>\n",
       "      <td>469</td>\n",
       "      <td>475</td>\n",
       "      <td>482</td>\n",
       "      <td>494</td>\n",
       "      <td>461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>484</td>\n",
       "      <td>502</td>\n",
       "      <td>528</td>\n",
       "      <td>489</td>\n",
       "      <td>466</td>\n",
       "      <td>481</td>\n",
       "      <td>402</td>\n",
       "      <td>478</td>\n",
       "      <td>487</td>\n",
       "      <td>468</td>\n",
       "      <td>...</td>\n",
       "      <td>479</td>\n",
       "      <td>452</td>\n",
       "      <td>435</td>\n",
       "      <td>486</td>\n",
       "      <td>508</td>\n",
       "      <td>481</td>\n",
       "      <td>504</td>\n",
       "      <td>495</td>\n",
       "      <td>511</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feat_0  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  \\\n",
       "0     485     477     537     479     452     471     491     476     475   \n",
       "1     483     458     460     487     587     475     526     479     485   \n",
       "2     487     542     499     468     448     471     442     478     480   \n",
       "3     480     491     510     485     495     472     417     474     502   \n",
       "4     484     502     528     489     466     481     402     478     487   \n",
       "\n",
       "   feat_9   ...    feat_491  feat_492  feat_493  feat_494  feat_495  feat_496  \\\n",
       "0     473   ...         481       477       485       511       485       481   \n",
       "1     469   ...         478       487       338       513       486       483   \n",
       "2     477   ...         481       492       650       506       501       480   \n",
       "3     476   ...         480       474       572       454       469       475   \n",
       "4     468   ...         479       452       435       486       508       481   \n",
       "\n",
       "   feat_497  feat_498  feat_499  target  \n",
       "0       479       475       496      -1  \n",
       "1       492       510       517      -1  \n",
       "2       489       499       498      -1  \n",
       "3       482       494       461       1  \n",
       "4       504       495       511       1  \n",
       "\n",
       "[5 rows x 501 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_uci_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating my three training sets that are 10% of the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s1_train_uci_10 = train_uci_df.sample(int(len(train_uci_df)*0.1), random_state=1)\n",
    "s2_train_uci_10 = train_uci_df.sample(int(len(train_uci_df)*0.1), random_state=10)\n",
    "s3_train_uci_10 = train_uci_df.sample(int(len(train_uci_df)*0.1), random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 200 entries, 674 to 926\n",
      "Columns: 501 entries, feat_0 to target\n",
      "dtypes: int64(501)\n",
      "memory usage: 784.4 KB\n"
     ]
    }
   ],
   "source": [
    "s1_train_uci_10.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These functions were discussed in class and will be used to determine redundant features.\n",
    "\n",
    "\n",
    "def calculate_r2_for_feature(data, feature, model):\n",
    "    new_data = data.drop(feature, axis=1)\n",
    "\n",
    "    X_train, \\\n",
    "    X_test,  \\\n",
    "    y_train, \\\n",
    "    y_test = train_test_split(\n",
    "        new_data,data[feature],test_size=0.25\n",
    "    )\n",
    "    \n",
    "    if model == 'DecisionTreeRegressor':\n",
    "        regressor = model()\n",
    "        regressor.fit(X_train, y_train)\n",
    "        score = regressor.score(X_test, y_test)\n",
    "\n",
    "    else:    \n",
    "        ss = StandardScaler()\n",
    "        ss.fit(X_train, y_train)\n",
    "        X_train_scaled = ss.transform(X_train)\n",
    "        X_test_scaled = ss.transform(X_test)\n",
    "\n",
    "        regressor = model()\n",
    "        regressor.fit(X_train_scaled,y_train)\n",
    "\n",
    "        score = regressor.score(X_test_scaled,y_test)\n",
    "    \n",
    "    return score\n",
    "\n",
    "\n",
    "def mean_r2_for_feature(data, feature, model):\n",
    "    scores = []\n",
    "    for _ in range(10):\n",
    "        scores.append(calculate_r2_for_feature(data, feature, model))\n",
    "        \n",
    "    scores = np.array(scores)\n",
    "    return scores.mean()\n",
    "\n",
    "\n",
    "def mean_r2_for_all_features(data, model):\n",
    "    ''' \n",
    "    This function takes the data and returns an r2 scores for every feature \n",
    "    in a DataFrame.\n",
    "    '''\n",
    "    mean_r2_dict = {}\n",
    "    \n",
    "    for feat in data.columns:\n",
    "        #data = data.sample(int(len(data)*.1)) # taking random sample of 10 percent of input data\n",
    "        score = mean_r2_for_feature(data, feat, model)\n",
    "        mean_r2_dict[feat] = score\n",
    "    \n",
    "    return mean_r2_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This cell is killing my t2.micro'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''This cell is killing my t2.micro'''\n",
    "\n",
    "# # this is using the mean_r2_for_all_features function, so its running all the features 10 times. I will store all of\n",
    "#     # results in a df.\n",
    "\n",
    "# %%timeit\n",
    "# dt_score_list = []\n",
    "\n",
    "# for _ in range(10):\n",
    "#     dt_score_list.append(mean_r2_for_all_features(s1_train_uci_10.drop('target', axis=1), DecisionTreeRegressor))\n",
    "\n",
    "# tree_s1_feature_scores_df = pd.DataFrame(dt_score_list)\n",
    "# tree_means = tree_s1_feature_scores_df.describe().T\n",
    "# tree_means_df = tree_means.sort_values('mean', ascending=False).head(20)[['mean', 'std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s1_dtree_mean_scores = []\n",
    "for col in s1_train_uci_10.drop('target', axis=1).columns:\n",
    "    s1_dtree_mean_scores.append(mean_r2_for_feature(s1_train_uci_10.drop('target', axis=1), col, DecisionTreeRegressor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.952069</td>\n",
       "      <td>feat_153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>0.950379</td>\n",
       "      <td>feat_442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>0.948254</td>\n",
       "      <td>feat_318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>0.944936</td>\n",
       "      <td>feat_433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>0.943598</td>\n",
       "      <td>feat_241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.937584</td>\n",
       "      <td>feat_28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>0.935187</td>\n",
       "      <td>feat_378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>0.933851</td>\n",
       "      <td>feat_475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.929555</td>\n",
       "      <td>feat_48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>0.928421</td>\n",
       "      <td>feat_472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>0.922009</td>\n",
       "      <td>feat_451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0.920975</td>\n",
       "      <td>feat_493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>0.916875</td>\n",
       "      <td>feat_453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>0.915456</td>\n",
       "      <td>feat_281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.912837</td>\n",
       "      <td>feat_64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.912712</td>\n",
       "      <td>feat_128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.885256</td>\n",
       "      <td>feat_105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0.885216</td>\n",
       "      <td>feat_336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>0.452879</td>\n",
       "      <td>feat_338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>0.411807</td>\n",
       "      <td>feat_455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>-0.582208</td>\n",
       "      <td>feat_221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>-0.654702</td>\n",
       "      <td>feat_446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>-0.661632</td>\n",
       "      <td>feat_251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>-0.678342</td>\n",
       "      <td>feat_383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>-0.747243</td>\n",
       "      <td>feat_171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1\n",
       "153  0.952069  feat_153\n",
       "442  0.950379  feat_442\n",
       "318  0.948254  feat_318\n",
       "433  0.944936  feat_433\n",
       "241  0.943598  feat_241\n",
       "28   0.937584   feat_28\n",
       "378  0.935187  feat_378\n",
       "475  0.933851  feat_475\n",
       "48   0.929555   feat_48\n",
       "472  0.928421  feat_472\n",
       "451  0.922009  feat_451\n",
       "493  0.920975  feat_493\n",
       "453  0.916875  feat_453\n",
       "281  0.915456  feat_281\n",
       "64   0.912837   feat_64\n",
       "128  0.912712  feat_128\n",
       "105  0.885256  feat_105\n",
       "336  0.885216  feat_336\n",
       "338  0.452879  feat_338\n",
       "455  0.411807  feat_455\n",
       "221 -0.582208  feat_221\n",
       "446 -0.654702  feat_446\n",
       "251 -0.661632  feat_251\n",
       "383 -0.678342  feat_383\n",
       "171 -0.747243  feat_171"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1_dtree_score_df = pd.DataFrame([s1_dtree_mean_scores, feature_col_names]).T.sort_values(0, ascending=False)\n",
    "s1_dtree_score_df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_correlated_cols = list(s1_dtree_score_df.head(20).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In the above calculation, I have exactly 20 features that have positive scores. There is 5 predictors and 15 linear\n",
    "    # combinations, so I think I've identified my noise! Next, I'm going to do this for the other random 10% samples\n",
    "    # and compare the results. Maybe keep the top 20 of all three for my next step, using lass/ridge/elastic net to\n",
    "    # remove features that are redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s2_dtree_mean_scores = []\n",
    "for col in s2_train_uci_10.drop('target', axis=1).columns:\n",
    "    s2_dtree_mean_scores.append(mean_r2_for_feature(s2_train_uci_10.drop('target', axis=1), col, DecisionTreeRegressor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s2_dtree_score_df = pd.DataFrame([s2_dtree_mean_scores, feature_col_names]).T.sort_values(0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_correlated_cols = list(s2_dtree_score_df.head(20).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s3_dtree_mean_scores = []\n",
    "for col in s3_train_uci_10.drop('target', axis=1).columns:\n",
    "    s3_dtree_mean_scores.append(mean_r2_for_feature(s3_train_uci_10.drop('target', axis=1), col, DecisionTreeRegressor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_dtree_score_df = pd.DataFrame([s3_dtree_mean_scores, feature_col_names]).T.sort_values(0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_correlated_cols = list(s3_dtree_score_df.head(20).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Added all of my top 20 columns for the 3 random 10% samples to see if there was variation, and they all got the exact\n",
    "    # same features. This is a good sign!\n",
    "\n",
    "len(set(s1_correlated_cols+s2_correlated_cols+s3_correlated_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[153,\n",
       " 442,\n",
       " 318,\n",
       " 433,\n",
       " 241,\n",
       " 28,\n",
       " 378,\n",
       " 475,\n",
       " 48,\n",
       " 472,\n",
       " 451,\n",
       " 493,\n",
       " 453,\n",
       " 281,\n",
       " 64,\n",
       " 128,\n",
       " 105,\n",
       " 336,\n",
       " 338,\n",
       " 455]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1_correlated_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_1</th>\n",
       "      <th>sample_2</th>\n",
       "      <th>sample_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>48</td>\n",
       "      <td>433</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>64</td>\n",
       "      <td>105</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>105</td>\n",
       "      <td>442</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>128</td>\n",
       "      <td>493</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>153</td>\n",
       "      <td>48</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>241</td>\n",
       "      <td>475</td>\n",
       "      <td>453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>281</td>\n",
       "      <td>64</td>\n",
       "      <td>442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>318</td>\n",
       "      <td>451</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>336</td>\n",
       "      <td>472</td>\n",
       "      <td>472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>338</td>\n",
       "      <td>338</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>378</td>\n",
       "      <td>336</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>433</td>\n",
       "      <td>153</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>442</td>\n",
       "      <td>318</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>451</td>\n",
       "      <td>453</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>453</td>\n",
       "      <td>128</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>455</td>\n",
       "      <td>455</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>472</td>\n",
       "      <td>378</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>475</td>\n",
       "      <td>281</td>\n",
       "      <td>493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>493</td>\n",
       "      <td>241</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sample_1  sample_2  sample_3\n",
       "5         28        28        48\n",
       "8         48       433       451\n",
       "14        64       105       336\n",
       "16       105       442        64\n",
       "15       128       493       475\n",
       "0        153        48       241\n",
       "4        241       475       453\n",
       "13       281        64       442\n",
       "2        318       451       128\n",
       "17       336       472       472\n",
       "18       338       338       455\n",
       "6        378       336       105\n",
       "3        433       153       318\n",
       "1        442       318        28\n",
       "10       451       453       433\n",
       "12       453       128       281\n",
       "19       455       455       338\n",
       "9        472       378       378\n",
       "7        475       281       493\n",
       "11       493       241       153"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_all_results_df = pd.DataFrame([s1_correlated_cols, s2_correlated_cols, s3_correlated_cols]).T\n",
    "s_all_results_df.columns = ['sample_1', 'sample_2', 'sample_3']\n",
    "s_all_results_df.sort('sample_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s1_corr = s1_train_uci_10[s1_correlated_cols].corr()\n",
    "s2_corr = s2_train_uci_10[s2_correlated_cols].corr()\n",
    "s3_corr = s3_train_uci_10[s3_correlated_cols].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s1_corr_desc = s1_corr.describe().T\n",
    "s1_corr_desc['mean'] = abs(s1_corr_desc['mean'].values)\n",
    "s1_corr_desc = s1_corr_desc.sort_values('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s2_corr_desc = s2_corr.describe().T\n",
    "s2_corr_desc['mean'] = abs(s2_corr_desc['mean'].values)\n",
    "s2_corr_desc = s2_corr_desc.sort_values('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s3_corr_desc = s1_corr.describe().T\n",
    "s3_corr_desc['mean'] = abs(s3_corr_desc['mean'].values)\n",
    "s3_corr_desc = s3_corr_desc.sort_values('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feat_241', 'feat_128', 'feat_378', 'feat_475', 'feat_338']"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_skb_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feat_455</th>\n",
       "      <td>0.044989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_318</th>\n",
       "      <td>0.058466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_451</th>\n",
       "      <td>0.059955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_28</th>\n",
       "      <td>0.060530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat_475</th>\n",
       "      <td>0.063081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              mean\n",
       "feat_455  0.044989\n",
       "feat_318  0.058466\n",
       "feat_451  0.059955\n",
       "feat_28   0.060530\n",
       "feat_475  0.063081"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_corr_desc[['mean']][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "low_corr_cols = list(set(list(s1_corr_desc.head(7).index)+list(s2_corr_desc.head(7).index)+list(s3_corr_desc.head(7).index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "low_corr_corr = s2_train_uci_10[low_corr_cols].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "\n",
    "corr = s1_corr\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I realized this might not be a good method for finding redundant features. Leaving here in case I use it later.\n",
    "s1_redundant_feats = list(set([433,153,128,472,28,451,318,281,433,475,241,28,451,48,378,453,493,64,336,128,105]))\n",
    "len(s1_redundant_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting the target values associated with each sample set.\n",
    "\n",
    "s1_train_uci_10_with_y = train_uci_df.sample(int(len(train_uci_df)*0.1), random_state=1)\n",
    "\n",
    "s2_train_uci_10_with_y = train_uci_df.sample(int(len(train_uci_df)*0.1), random_state=10)\n",
    "\n",
    "s3_train_uci_10_with_y = train_uci_df.sample(int(len(train_uci_df)*0.1), random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_s1 = s1_train_uci_10_with_y[s1_correlated_cols+[-1]]['target']\n",
    "\n",
    "y_s2 = s2_train_uci_10_with_y[s2_correlated_cols+[-1]]['target']\n",
    "\n",
    "y_s3 = s3_train_uci_10_with_y[s3_correlated_cols+[-1]]['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feat_241', 'feat_475', 'feat_64', 'feat_128', 'feat_336']"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results f-classif: ['feat_241', 'feat_475', 'feat_64', 'feat_128', 'feat_336']\n",
    "skb_s1 = SelectKBest(k=5)\n",
    "skb_s1.fit(s1_train_uci_10[s1_correlated_cols], y_s1)\n",
    "s1_skb_feats = np.where(skb_s1.get_support())[0]\n",
    "s1_skb_cols = list(s1_train_uci_10[s1_correlated_cols][s1_skb_feats].head().columns)\n",
    "\n",
    "s1_skb_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feat_48', 'feat_475', 'feat_378', 'feat_241', 'feat_128']"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results f-classif: ['feat_48', 'feat_475', 'feat_378', 'feat_241', 'feat_128']\n",
    "\n",
    "skb_s2 = SelectKBest(k=5)\n",
    "skb_s2.fit(s2_train_uci_10[s2_correlated_cols], y_s2)\n",
    "s2_skb_feats = np.where(skb_s2.get_support())[0]\n",
    "s2_skb_cols = list(s2_train_uci_10[s2_correlated_cols][s2_skb_feats].head().columns)\n",
    "\n",
    "s2_skb_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feat_241', 'feat_128', 'feat_378', 'feat_475', 'feat_338']"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results f-classif: ['feat_241', 'feat_128', 'feat_378', 'feat_475', 'feat_338']\n",
    "\n",
    "skb_s3 = SelectKBest(k=5)\n",
    "skb_s3.fit(s3_train_uci_10[s3_correlated_cols], y_s3)\n",
    "s3_skb_feats = np.where(skb_s3.get_support())[0]\n",
    "s3_skb_cols = list(s3_train_uci_10[s3_correlated_cols][s3_skb_feats].head().columns)\n",
    "\n",
    "s3_skb_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feat_128',\n",
       " 'feat_241',\n",
       " 'feat_336',\n",
       " 'feat_338',\n",
       " 'feat_378',\n",
       " 'feat_475',\n",
       " 'feat_48',\n",
       " 'feat_64'}"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features that show in all three of the SelectKBest fits: 128, 241, 475\n",
    "# Features that show twice: 378\n",
    "# Features that show once: 64, 48, 338, 336\n",
    "\n",
    "skb_all_samp_feats = set(s1_skb_cols + s2_skb_cols + s3_skb_cols)\n",
    "skb_all_samp_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feat_153',\n",
       " 'feat_442',\n",
       " 'feat_241',\n",
       " 'feat_378',\n",
       " 'feat_453',\n",
       " 'feat_105',\n",
       " 'feat_336',\n",
       " 'feat_455']"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Found with Lasso: ['feat_442', 'feat_378', 'feat_475', 'feat_105', 'feat_336']\n",
    "# Found with ElasticNet: ['feat_153','feat_442','feat_241','feat_378','feat_453','feat_105','feat_336','feat_455']\n",
    "    \n",
    "sfm_s1 = SelectFromModel(ElasticNet(), threshold='mean')\n",
    "sfm_s1.fit(s1_train_uci_10[s1_correlated_cols], y_s1)\n",
    "s1_sfm_feats = np.where(sfm_s1.get_support())[0]\n",
    "s1_sfm_cols = list(s1_train_uci_10[s1_correlated_cols][s1_sfm_feats].head().columns)\n",
    "s1_sfm_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feat_475', 'feat_336', 'feat_241', 'feat_64', 'feat_472']"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Found with Lasso: ['feat_475', 'feat_453', 'feat_64']\n",
    "# Found with ElasticNet: ['feat_475', 'feat_336', 'feat_241', 'feat_64', 'feat_472']\n",
    "\n",
    "sfm_s2 = SelectFromModel(ElasticNet(), threshold='mean')\n",
    "sfm_s2.fit(s1_train_uci_10[s2_correlated_cols], y_s2)\n",
    "s2_sfm_feats = np.where(sfm_s2.get_support())[0]\n",
    "s2_sfm_cols = list(s2_train_uci_10[s2_correlated_cols][s2_sfm_feats].head().columns)\n",
    "s2_sfm_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feat_241',\n",
       " 'feat_318',\n",
       " 'feat_493',\n",
       " 'feat_378',\n",
       " 'feat_475',\n",
       " 'feat_455',\n",
       " 'feat_338']"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Found with Lasso: ['feat_318', 'feat_378', 'feat_475', 'feat_338']\n",
    "# Found with ElasticNet: ['feat_241','feat_318','feat_493','feat_378','feat_475','feat_455','feat_338']\n",
    "\n",
    "sfm_s3 = SelectFromModel(ElasticNet(), threshold='mean')\n",
    "sfm_s3.fit(s3_train_uci_10[s3_correlated_cols], y_s3)\n",
    "s3_sfm_feats = np.where(sfm_s3.get_support())[0]\n",
    "s3_sfm_cols = list(s3_train_uci_10[s3_correlated_cols][s3_sfm_feats].head().columns)\n",
    "s3_sfm_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feat_105',\n",
       " 'feat_153',\n",
       " 'feat_241',\n",
       " 'feat_318',\n",
       " 'feat_336',\n",
       " 'feat_338',\n",
       " 'feat_378',\n",
       " 'feat_442',\n",
       " 'feat_453',\n",
       " 'feat_455',\n",
       " 'feat_472',\n",
       " 'feat_475',\n",
       " 'feat_493',\n",
       " 'feat_64']"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features that show in all three of the SelectFromModel fits: 475\n",
    "# Features that show twice: 378\n",
    "# Features that show once: 64, 105, 318, 336, 338, 442, 453\n",
    "\n",
    "sfm_all_samp_feats = sorted(list(set(s1_sfm_cols + s2_sfm_cols + s3_sfm_cols)))\n",
    "sfm_all_samp_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feat_105',\n",
       " 'feat_128',\n",
       " 'feat_241',\n",
       " 'feat_318',\n",
       " 'feat_336',\n",
       " 'feat_338',\n",
       " 'feat_378',\n",
       " 'feat_442',\n",
       " 'feat_453',\n",
       " 'feat_475',\n",
       " 'feat_48',\n",
       " 'feat_64'}"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features that appear in both SFM and SKB: 64, 336, 338, 378, 475\n",
    "# I feel like I should also consider 128 and 241 because that appeared in all three sample sets for SKB.\n",
    "\n",
    "sfm_skb_all_feats_combo = set(list(skb_all_samp_feats) + list(sfm_all_samp_feats))\n",
    "sfm_skb_all_feats_combo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Initial thoughts:\n",
    "\n",
    "#### UCI Web Data\n",
    "\n",
    "Using the unsupervised learning technique where a regressor is used to compare every feature (column) against the rest of the dataset, I was able to find exactly 20 features that have mean R^2 scores that are positive, and most of them are very high (in the 0.8-0.9 range) for all three of the random data subsets. Since 480/500 of the features in the madelon dataset are noise, I believe that this is a good indication that I have found my 5 predictor features and the 15 linear combinations.\n",
    "\n",
    "Using SelectKBest with k=5 on my 3 random data subsets, I was able to identify 8 unique features. Using SelectFromModel with the Lasso estimator, I was able to identify 9. Between these two lists of features, only 5 are the same. SelectFromModel returned 5 for the first dataset, 3 for the second, and 4 for the third. Since the full dataset has five important features, I think that the first sample is the most representative of the data. \n",
    "\n",
    "Moving forward, I will use GridSearchCV to tune my model hyperparameters and try various combonations of the important features I identified, starting with the 5 features that I found in both my SFM and SKB models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
