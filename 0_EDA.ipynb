{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3 - Madelon Data Analysis\n",
    "## Step 0: EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching package metadata .............\n",
      "Solving package specifications: .\n",
      "\n",
      "# All requested packages already installed.\n",
      "# packages in environment at /opt/conda:\n",
      "#\n",
      "psycopg2                  2.7.3.1          py36h369a60c_0    defaults\n"
     ]
    }
   ],
   "source": [
    "!conda install psycopg2 --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run madelon_analyzer.py\n",
    "%run pickle_jar.py\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>feat_000</th>\n",
       "      <th>feat_001</th>\n",
       "      <th>feat_002</th>\n",
       "      <th>feat_003</th>\n",
       "      <th>feat_004</th>\n",
       "      <th>feat_005</th>\n",
       "      <th>feat_006</th>\n",
       "      <th>feat_007</th>\n",
       "      <th>feat_008</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_991</th>\n",
       "      <th>feat_992</th>\n",
       "      <th>feat_993</th>\n",
       "      <th>feat_994</th>\n",
       "      <th>feat_995</th>\n",
       "      <th>feat_996</th>\n",
       "      <th>feat_997</th>\n",
       "      <th>feat_998</th>\n",
       "      <th>feat_999</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112013</td>\n",
       "      <td>0.874623</td>\n",
       "      <td>-0.433386</td>\n",
       "      <td>1.282504</td>\n",
       "      <td>0.440211</td>\n",
       "      <td>-0.729979</td>\n",
       "      <td>-0.121770</td>\n",
       "      <td>-0.756523</td>\n",
       "      <td>-0.311089</td>\n",
       "      <td>-1.047285</td>\n",
       "      <td>...</td>\n",
       "      <td>1.954668</td>\n",
       "      <td>1.426505</td>\n",
       "      <td>0.396491</td>\n",
       "      <td>-0.705992</td>\n",
       "      <td>-0.312878</td>\n",
       "      <td>1.045555</td>\n",
       "      <td>-2.495671</td>\n",
       "      <td>1.039028</td>\n",
       "      <td>2.045024</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107302</td>\n",
       "      <td>1.122571</td>\n",
       "      <td>0.275028</td>\n",
       "      <td>-0.296846</td>\n",
       "      <td>0.752930</td>\n",
       "      <td>-0.473619</td>\n",
       "      <td>-0.819199</td>\n",
       "      <td>0.022044</td>\n",
       "      <td>-2.374956</td>\n",
       "      <td>2.130340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670175</td>\n",
       "      <td>0.168732</td>\n",
       "      <td>-1.674614</td>\n",
       "      <td>0.968680</td>\n",
       "      <td>-2.186223</td>\n",
       "      <td>-0.855602</td>\n",
       "      <td>0.118787</td>\n",
       "      <td>-0.765210</td>\n",
       "      <td>-0.077157</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10607</td>\n",
       "      <td>-0.246912</td>\n",
       "      <td>-0.004445</td>\n",
       "      <td>0.805970</td>\n",
       "      <td>-1.743573</td>\n",
       "      <td>-0.042794</td>\n",
       "      <td>1.096977</td>\n",
       "      <td>-0.054843</td>\n",
       "      <td>-0.661225</td>\n",
       "      <td>0.473623</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.371504</td>\n",
       "      <td>0.905834</td>\n",
       "      <td>-1.494369</td>\n",
       "      <td>-0.157062</td>\n",
       "      <td>-0.366484</td>\n",
       "      <td>0.746824</td>\n",
       "      <td>1.247538</td>\n",
       "      <td>-1.521214</td>\n",
       "      <td>1.343050</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150235</td>\n",
       "      <td>-0.382419</td>\n",
       "      <td>-0.304121</td>\n",
       "      <td>1.141382</td>\n",
       "      <td>-0.414432</td>\n",
       "      <td>-0.248223</td>\n",
       "      <td>1.065871</td>\n",
       "      <td>-0.729584</td>\n",
       "      <td>-3.064909</td>\n",
       "      <td>0.430729</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.627376</td>\n",
       "      <td>1.258283</td>\n",
       "      <td>-0.653569</td>\n",
       "      <td>-1.199824</td>\n",
       "      <td>-1.752736</td>\n",
       "      <td>-1.303956</td>\n",
       "      <td>-0.298844</td>\n",
       "      <td>0.772032</td>\n",
       "      <td>0.506764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90111</td>\n",
       "      <td>1.347762</td>\n",
       "      <td>0.746815</td>\n",
       "      <td>0.362632</td>\n",
       "      <td>0.846772</td>\n",
       "      <td>-1.262384</td>\n",
       "      <td>1.364104</td>\n",
       "      <td>-0.075601</td>\n",
       "      <td>0.352371</td>\n",
       "      <td>-1.001628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.431206</td>\n",
       "      <td>1.143164</td>\n",
       "      <td>-0.381148</td>\n",
       "      <td>1.055597</td>\n",
       "      <td>-0.198674</td>\n",
       "      <td>-0.309390</td>\n",
       "      <td>0.105413</td>\n",
       "      <td>0.611066</td>\n",
       "      <td>0.372415</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      _id  feat_000  feat_001  feat_002  feat_003  feat_004  feat_005  \\\n",
       "0  112013  0.874623 -0.433386  1.282504  0.440211 -0.729979 -0.121770   \n",
       "1  107302  1.122571  0.275028 -0.296846  0.752930 -0.473619 -0.819199   \n",
       "2   10607 -0.246912 -0.004445  0.805970 -1.743573 -0.042794  1.096977   \n",
       "3  150235 -0.382419 -0.304121  1.141382 -0.414432 -0.248223  1.065871   \n",
       "4   90111  1.347762  0.746815  0.362632  0.846772 -1.262384  1.364104   \n",
       "\n",
       "   feat_006  feat_007  feat_008   ...    feat_991  feat_992  feat_993  \\\n",
       "0 -0.756523 -0.311089 -1.047285   ...    1.954668  1.426505  0.396491   \n",
       "1  0.022044 -2.374956  2.130340   ...    0.670175  0.168732 -1.674614   \n",
       "2 -0.054843 -0.661225  0.473623   ...   -0.371504  0.905834 -1.494369   \n",
       "3 -0.729584 -3.064909  0.430729   ...   -0.627376  1.258283 -0.653569   \n",
       "4 -0.075601  0.352371 -1.001628   ...    0.431206  1.143164 -0.381148   \n",
       "\n",
       "   feat_994  feat_995  feat_996  feat_997  feat_998  feat_999  target  \n",
       "0 -0.705992 -0.312878  1.045555 -2.495671  1.039028  2.045024       0  \n",
       "1  0.968680 -2.186223 -0.855602  0.118787 -0.765210 -0.077157       0  \n",
       "2 -0.157062 -0.366484  0.746824  1.247538 -1.521214  1.343050       0  \n",
       "3 -1.199824 -1.752736 -1.303956 -0.298844  0.772032  0.506764       1  \n",
       "4  1.055597 -0.198674 -0.309390  0.105413  0.611066  0.372415       0  \n",
       "\n",
       "[5 rows x 1002 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_6506_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data\n",
    "\n",
    "Below is EDA of the expanded Madelon dataset with 1000 features and 200,000 observations. To start with, I've imported 3000 rows and will be performing unsupervised learning techniques to find and remove the noise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def con_cur_to_class_db():\n",
    "    '''This function will return a connection and cursor object from the expanded Madelon data that was provided \n",
    "    by the instructors. It is not the downloaded version of the data from the UCI website.'''\n",
    "    \n",
    "    con = pg2.connect(host='34.211.227.227',\n",
    "                  dbname='postgres',\n",
    "                  user='postgres')\n",
    "    cur = con.cursor(cursor_factory=RealDictCursor)\n",
    "    \n",
    "    return con, cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this cell, I'm going to try and get a representative sample of the population\n",
    "# https://www.surveymonkey.com/mp/sample-size-calculator/ (confidence level = 90%, margin of error = 1)\n",
    "\n",
    "# con_6506, cur_6506 = con_cur_to_class_db()\n",
    "# %time cur_6506.execute('SELECT * FROM madelon ORDER BY random() LIMIT 6506')\n",
    "# %time results_6506 = cur_6506.fetchall()\n",
    "# con_6506.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dataframe of just 6506 samples for initial testing.\n",
    "\n",
    "# samp_6506_bd_df = pd.DataFrame(results_6506)\n",
    "# pd.to_pickle(samp_6506_bd_df, '6506_sample_big_data.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samp_6506_bd_df.index = samp_6506_bd_df['_id']\n",
    "# samp_6506_bd_df = samp_6506_bd_df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# con, cur = con_cur_to_class_db()\n",
    "# %time cur.execute('SELECT * FROM madelon ORDER BY random() LIMIT 3000')\n",
    "# %time results = cur.fetchall()\n",
    "# con.close()\n",
    "\n",
    "# # Dataframe of just 3000 samples for initial testing.\n",
    "\n",
    "# samp_3000_bd_df = pd.DataFrame(results)\n",
    "\n",
    "# pd.to_pickle(samp_3000_bd_df, '3000_sample_big_data.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>feat_000</th>\n",
       "      <th>feat_001</th>\n",
       "      <th>feat_002</th>\n",
       "      <th>feat_003</th>\n",
       "      <th>feat_004</th>\n",
       "      <th>feat_005</th>\n",
       "      <th>feat_006</th>\n",
       "      <th>feat_007</th>\n",
       "      <th>feat_008</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_991</th>\n",
       "      <th>feat_992</th>\n",
       "      <th>feat_993</th>\n",
       "      <th>feat_994</th>\n",
       "      <th>feat_995</th>\n",
       "      <th>feat_996</th>\n",
       "      <th>feat_997</th>\n",
       "      <th>feat_998</th>\n",
       "      <th>feat_999</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112013</td>\n",
       "      <td>0.874623</td>\n",
       "      <td>-0.433386</td>\n",
       "      <td>1.282504</td>\n",
       "      <td>0.440211</td>\n",
       "      <td>-0.729979</td>\n",
       "      <td>-0.121770</td>\n",
       "      <td>-0.756523</td>\n",
       "      <td>-0.311089</td>\n",
       "      <td>-1.047285</td>\n",
       "      <td>...</td>\n",
       "      <td>1.954668</td>\n",
       "      <td>1.426505</td>\n",
       "      <td>0.396491</td>\n",
       "      <td>-0.705992</td>\n",
       "      <td>-0.312878</td>\n",
       "      <td>1.045555</td>\n",
       "      <td>-2.495671</td>\n",
       "      <td>1.039028</td>\n",
       "      <td>2.045024</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107302</td>\n",
       "      <td>1.122571</td>\n",
       "      <td>0.275028</td>\n",
       "      <td>-0.296846</td>\n",
       "      <td>0.752930</td>\n",
       "      <td>-0.473619</td>\n",
       "      <td>-0.819199</td>\n",
       "      <td>0.022044</td>\n",
       "      <td>-2.374956</td>\n",
       "      <td>2.130340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670175</td>\n",
       "      <td>0.168732</td>\n",
       "      <td>-1.674614</td>\n",
       "      <td>0.968680</td>\n",
       "      <td>-2.186223</td>\n",
       "      <td>-0.855602</td>\n",
       "      <td>0.118787</td>\n",
       "      <td>-0.765210</td>\n",
       "      <td>-0.077157</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10607</td>\n",
       "      <td>-0.246912</td>\n",
       "      <td>-0.004445</td>\n",
       "      <td>0.805970</td>\n",
       "      <td>-1.743573</td>\n",
       "      <td>-0.042794</td>\n",
       "      <td>1.096977</td>\n",
       "      <td>-0.054843</td>\n",
       "      <td>-0.661225</td>\n",
       "      <td>0.473623</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.371504</td>\n",
       "      <td>0.905834</td>\n",
       "      <td>-1.494369</td>\n",
       "      <td>-0.157062</td>\n",
       "      <td>-0.366484</td>\n",
       "      <td>0.746824</td>\n",
       "      <td>1.247538</td>\n",
       "      <td>-1.521214</td>\n",
       "      <td>1.343050</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150235</td>\n",
       "      <td>-0.382419</td>\n",
       "      <td>-0.304121</td>\n",
       "      <td>1.141382</td>\n",
       "      <td>-0.414432</td>\n",
       "      <td>-0.248223</td>\n",
       "      <td>1.065871</td>\n",
       "      <td>-0.729584</td>\n",
       "      <td>-3.064909</td>\n",
       "      <td>0.430729</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.627376</td>\n",
       "      <td>1.258283</td>\n",
       "      <td>-0.653569</td>\n",
       "      <td>-1.199824</td>\n",
       "      <td>-1.752736</td>\n",
       "      <td>-1.303956</td>\n",
       "      <td>-0.298844</td>\n",
       "      <td>0.772032</td>\n",
       "      <td>0.506764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90111</td>\n",
       "      <td>1.347762</td>\n",
       "      <td>0.746815</td>\n",
       "      <td>0.362632</td>\n",
       "      <td>0.846772</td>\n",
       "      <td>-1.262384</td>\n",
       "      <td>1.364104</td>\n",
       "      <td>-0.075601</td>\n",
       "      <td>0.352371</td>\n",
       "      <td>-1.001628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.431206</td>\n",
       "      <td>1.143164</td>\n",
       "      <td>-0.381148</td>\n",
       "      <td>1.055597</td>\n",
       "      <td>-0.198674</td>\n",
       "      <td>-0.309390</td>\n",
       "      <td>0.105413</td>\n",
       "      <td>0.611066</td>\n",
       "      <td>0.372415</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      _id  feat_000  feat_001  feat_002  feat_003  feat_004  feat_005  \\\n",
       "0  112013  0.874623 -0.433386  1.282504  0.440211 -0.729979 -0.121770   \n",
       "1  107302  1.122571  0.275028 -0.296846  0.752930 -0.473619 -0.819199   \n",
       "2   10607 -0.246912 -0.004445  0.805970 -1.743573 -0.042794  1.096977   \n",
       "3  150235 -0.382419 -0.304121  1.141382 -0.414432 -0.248223  1.065871   \n",
       "4   90111  1.347762  0.746815  0.362632  0.846772 -1.262384  1.364104   \n",
       "\n",
       "   feat_006  feat_007  feat_008   ...    feat_991  feat_992  feat_993  \\\n",
       "0 -0.756523 -0.311089 -1.047285   ...    1.954668  1.426505  0.396491   \n",
       "1  0.022044 -2.374956  2.130340   ...    0.670175  0.168732 -1.674614   \n",
       "2 -0.054843 -0.661225  0.473623   ...   -0.371504  0.905834 -1.494369   \n",
       "3 -0.729584 -3.064909  0.430729   ...   -0.627376  1.258283 -0.653569   \n",
       "4 -0.075601  0.352371 -1.001628   ...    0.431206  1.143164 -0.381148   \n",
       "\n",
       "   feat_994  feat_995  feat_996  feat_997  feat_998  feat_999  target  \n",
       "0 -0.705992 -0.312878  1.045555 -2.495671  1.039028  2.045024       0  \n",
       "1  0.968680 -2.186223 -0.855602  0.118787 -0.765210 -0.077157       0  \n",
       "2 -0.157062 -0.366484  0.746824  1.247538 -1.521214  1.343050       0  \n",
       "3 -1.199824 -1.752736 -1.303956 -0.298844  0.772032  0.506764       1  \n",
       "4  1.055597 -0.198674 -0.309390  0.105413  0.611066  0.372415       0  \n",
       "\n",
       "[5 rows x 1002 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp_6506_bd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Columns: 1000 entries, feat_000 to feat_999\n",
      "dtypes: float64(1000)\n",
      "memory usage: 1.5 MB\n"
     ]
    }
   ],
   "source": [
    "X = samp_3000_bd_df.iloc[:200,1:-1]\n",
    "X_2 = samp_3000_bd_df.iloc[200:400,1:-1]\n",
    "X_3 = samp_3000_bd_df.iloc[400:600,1:-1]\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    200.000000\n",
       "mean       0.001668\n",
       "std        1.019437\n",
       "min       -2.800271\n",
       "25%       -0.681074\n",
       "50%        0.001271\n",
       "75%        0.682078\n",
       "max        2.826687\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From this, I can tell that the big uci dataset is already normal\n",
    "X.describe().T.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = samp_3000_bd_df.iloc[:200,-1:]\n",
    "y_2 = samp_3000_bd_df.iloc[200:400,-1:]\n",
    "y_3 = samp_3000_bd_df.iloc[400:600,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=42, test_size=0.333)\n",
    "X_2_train, X_2_test, y_2_train, y_2_test = train_test_split(X_2,y_2, random_state=42, test_size=0.333)\n",
    "X_3_train, X_3_test, y_3_train, y_3_test = train_test_split(X_3,y_3, random_state=42, test_size=0.333)\n",
    "\n",
    "train_df = pd.merge(X_train, y_train, left_index=True, right_index=True)\n",
    "train_2_df = pd.merge(X_2_train, y_2_train, left_index=True, right_index=True)\n",
    "train_3_df = pd.merge(X_3_train, y_3_train, left_index=True, right_index=True)\n",
    "\n",
    "test_df = pd.merge(X_test, y_test, left_index=True, right_index=True)\n",
    "test_2_df = pd.merge(X_2_test, y_2_test, left_index=True, right_index=True)\n",
    "test_3_df = pd.merge(X_3_test, y_3_test, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 59s, sys: 160 ms, total: 6min 59s\n",
      "Wall time: 6min 59s\n"
     ]
    }
   ],
   "source": [
    "# NOTE: cell takes 7 minutes to run\n",
    "\n",
    "ma = madelon_analyzer(train_df, test_df)\n",
    "\n",
    "%time r2_bd_df = ma.mean_r2_for_all_features(train_df, DecisionTreeRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_bd_df = r2_bd_df.sort_values('r2_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.to_pickle(r2_bd_df, 'mean_r2_bd_sample_1.p')\n",
    "# r2_bd_df = pd.read_pickle('Data/mean_r2_bd_sample_1.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ma_2 = madelon_analyzer(train_2_df, test_2_df)\n",
    "# ma_3 = madelon_analyzer(train_3_df, test_3_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 6s, sys: 120 ms, total: 7min 6s\n",
      "Wall time: 7min 6s\n"
     ]
    }
   ],
   "source": [
    "# %time r2_bd_2_df = ma_2.mean_r2_for_all_features(train_2_df, DecisionTreeRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2_bd_2_df = r2_bd_2_df.sort_values('r2_score', ascending=False)\n",
    "# pd.to_pickle(r2_bd_2_df, 'mean_r2_bd_sample_2.p')\n",
    "r2_bd_2_df = pd.read_pickle('Data/mean_r2_bd_sample_2.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 48s, sys: 90 ms, total: 6min 48s\n",
      "Wall time: 6min 48s\n"
     ]
    }
   ],
   "source": [
    "# %time r2_bd_3_df = ma_3.mean_r2_for_all_features(train_3_df, DecisionTreeRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2_bd_3_df = r2_bd_3_df.sort_values('r2_score', ascending=False)\n",
    "# pd.to_pickle(r2_bd_3_df, 'mean_r2_bd_sample_3.p')\n",
    "r2_bd_3_df = pd.read_pickle('Data/mean_r2_bd_sample_3.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2_score</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>0.806627</td>\n",
       "      <td>feat_639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>0.754375</td>\n",
       "      <td>feat_956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>0.573237</td>\n",
       "      <td>feat_315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>0.519356</td>\n",
       "      <td>feat_724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>0.475584</td>\n",
       "      <td>feat_867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0.472721</td>\n",
       "      <td>feat_336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>0.467021</td>\n",
       "      <td>feat_269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>0.390734</td>\n",
       "      <td>feat_701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>0.375489</td>\n",
       "      <td>feat_920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>0.315068</td>\n",
       "      <td>feat_681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.291377</td>\n",
       "      <td>feat_395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>0.255419</td>\n",
       "      <td>feat_736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>0.250702</td>\n",
       "      <td>feat_257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>0.23143</td>\n",
       "      <td>feat_829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>0.182425</td>\n",
       "      <td>feat_341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>0.176203</td>\n",
       "      <td>feat_769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.172482</td>\n",
       "      <td>feat_504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>0.124137</td>\n",
       "      <td>feat_808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>-0.0130461</td>\n",
       "      <td>feat_308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>-0.329475</td>\n",
       "      <td>feat_526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      r2_score   feature\n",
       "639   0.806627  feat_639\n",
       "956   0.754375  feat_956\n",
       "315   0.573237  feat_315\n",
       "724   0.519356  feat_724\n",
       "867   0.475584  feat_867\n",
       "336   0.472721  feat_336\n",
       "269   0.467021  feat_269\n",
       "701   0.390734  feat_701\n",
       "920   0.375489  feat_920\n",
       "681   0.315068  feat_681\n",
       "395   0.291377  feat_395\n",
       "736   0.255419  feat_736\n",
       "257   0.250702  feat_257\n",
       "829    0.23143  feat_829\n",
       "341   0.182425  feat_341\n",
       "769   0.176203  feat_769\n",
       "504   0.172482  feat_504\n",
       "808   0.124137  feat_808\n",
       "308 -0.0130461  feat_308\n",
       "526  -0.329475  feat_526"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_bd_3_df[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2_score</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>0.845707</td>\n",
       "      <td>feat_639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>0.808271</td>\n",
       "      <td>feat_956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>0.575084</td>\n",
       "      <td>feat_315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>0.485985</td>\n",
       "      <td>feat_867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>0.462097</td>\n",
       "      <td>feat_341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>0.417449</td>\n",
       "      <td>feat_701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>0.409274</td>\n",
       "      <td>feat_724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>0.347879</td>\n",
       "      <td>feat_526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>0.327253</td>\n",
       "      <td>feat_769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>0.314855</td>\n",
       "      <td>feat_829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>0.311286</td>\n",
       "      <td>feat_269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0.293929</td>\n",
       "      <td>feat_336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>0.290956</td>\n",
       "      <td>feat_920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.284413</td>\n",
       "      <td>feat_395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>0.279773</td>\n",
       "      <td>feat_257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>0.211217</td>\n",
       "      <td>feat_808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>0.200698</td>\n",
       "      <td>feat_736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.198587</td>\n",
       "      <td>feat_504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>0.188266</td>\n",
       "      <td>feat_681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>0.0590268</td>\n",
       "      <td>feat_308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      r2_score   feature\n",
       "639   0.845707  feat_639\n",
       "956   0.808271  feat_956\n",
       "315   0.575084  feat_315\n",
       "867   0.485985  feat_867\n",
       "341   0.462097  feat_341\n",
       "701   0.417449  feat_701\n",
       "724   0.409274  feat_724\n",
       "526   0.347879  feat_526\n",
       "769   0.327253  feat_769\n",
       "829   0.314855  feat_829\n",
       "269   0.311286  feat_269\n",
       "336   0.293929  feat_336\n",
       "920   0.290956  feat_920\n",
       "395   0.284413  feat_395\n",
       "257   0.279773  feat_257\n",
       "808   0.211217  feat_808\n",
       "736   0.200698  feat_736\n",
       "504   0.198587  feat_504\n",
       "681   0.188266  feat_681\n",
       "308  0.0590268  feat_308"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_bd_2_df[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First 20 features are all the same for the first 3 samples of the big madelon dataset\n",
    "\n",
    "first_3_bd_samps_correlated_feats_list = \\\n",
    "list(set(list(r2_bd_df[:20].index)+list(r2_bd_2_df[:20].index)+list(r2_bd_3_df[:20].index)))\n",
    "\n",
    "len(first_3_bd_samps_correlated_feats_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 230 ms, sys: 40 ms, total: 270 ms\n",
      "Wall time: 571 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_3_bd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.685500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_score</th>\n",
       "      <td>0.523333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             first_3_bd\n",
       "train_score    0.685500\n",
       "val_score      0.523333"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma_first_3 = madelon_analyzer(samp_3000_bd_df[:2000], samp_3000_bd_df[2000:2600])\n",
    "%time ma_first_3_benchmark = ma_first_3.train_val_scorer_df_maker(first_3_bd_samps_correlated_feats_list,\\\n",
    "                                                                  'first_3_bd')\n",
    "ma_first_3_benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.47 s, sys: 20 ms, total: 1.49 s\n",
      "Wall time: 3.3 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_3_bd_6506</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.678600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_score</th>\n",
       "      <td>0.518592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             first_3_bd_6506\n",
       "train_score         0.678600\n",
       "val_score           0.518592"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma_first_3_6506 = madelon_analyzer(samp_6506_bd_df[:5000], samp_6506_bd_df[5000:])\n",
    "%time ma_first_3_benchmark_6506 = ma_first_3_6506.train_val_scorer_df_maker(first_3_bd_samps_correlated_feats_list,\\\n",
    "                                                                  'first_3_bd_6506')\n",
    "ma_first_3_benchmark_6506"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ma_6506 = madelon_analyzer(samp_6506_bd_df.iloc[:200,500:], samp_6506_bd_df.iloc[500:600,500:])\n",
    "\n",
    "# %time r2_bd_6506_df = ma_6506.mean_r2_for_all_features(samp_6506_bd_df.iloc[:500,:], DecisionTreeRegressor)\n",
    "\n",
    "# r2_bd_6506_df = r2_bd_6506_df.sort_values('r2_score', ascending=False)\n",
    "\n",
    "# pd.to_pickle(r2_bd_6506_df, 'mean_r2_bd_sample_6506.p')\n",
    "# r2_bd_6506_df = pd.read_pickle('mean_r2_bd_sample_6506.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>feat_000</th>\n",
       "      <th>feat_001</th>\n",
       "      <th>feat_002</th>\n",
       "      <th>feat_003</th>\n",
       "      <th>feat_004</th>\n",
       "      <th>feat_005</th>\n",
       "      <th>feat_006</th>\n",
       "      <th>feat_007</th>\n",
       "      <th>feat_008</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_991</th>\n",
       "      <th>feat_992</th>\n",
       "      <th>feat_993</th>\n",
       "      <th>feat_994</th>\n",
       "      <th>feat_995</th>\n",
       "      <th>feat_996</th>\n",
       "      <th>feat_997</th>\n",
       "      <th>feat_998</th>\n",
       "      <th>feat_999</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112013</td>\n",
       "      <td>0.874623</td>\n",
       "      <td>-0.433386</td>\n",
       "      <td>1.282504</td>\n",
       "      <td>0.440211</td>\n",
       "      <td>-0.729979</td>\n",
       "      <td>-0.121770</td>\n",
       "      <td>-0.756523</td>\n",
       "      <td>-0.311089</td>\n",
       "      <td>-1.047285</td>\n",
       "      <td>...</td>\n",
       "      <td>1.954668</td>\n",
       "      <td>1.426505</td>\n",
       "      <td>0.396491</td>\n",
       "      <td>-0.705992</td>\n",
       "      <td>-0.312878</td>\n",
       "      <td>1.045555</td>\n",
       "      <td>-2.495671</td>\n",
       "      <td>1.039028</td>\n",
       "      <td>2.045024</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107302</td>\n",
       "      <td>1.122571</td>\n",
       "      <td>0.275028</td>\n",
       "      <td>-0.296846</td>\n",
       "      <td>0.752930</td>\n",
       "      <td>-0.473619</td>\n",
       "      <td>-0.819199</td>\n",
       "      <td>0.022044</td>\n",
       "      <td>-2.374956</td>\n",
       "      <td>2.130340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670175</td>\n",
       "      <td>0.168732</td>\n",
       "      <td>-1.674614</td>\n",
       "      <td>0.968680</td>\n",
       "      <td>-2.186223</td>\n",
       "      <td>-0.855602</td>\n",
       "      <td>0.118787</td>\n",
       "      <td>-0.765210</td>\n",
       "      <td>-0.077157</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10607</td>\n",
       "      <td>-0.246912</td>\n",
       "      <td>-0.004445</td>\n",
       "      <td>0.805970</td>\n",
       "      <td>-1.743573</td>\n",
       "      <td>-0.042794</td>\n",
       "      <td>1.096977</td>\n",
       "      <td>-0.054843</td>\n",
       "      <td>-0.661225</td>\n",
       "      <td>0.473623</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.371504</td>\n",
       "      <td>0.905834</td>\n",
       "      <td>-1.494369</td>\n",
       "      <td>-0.157062</td>\n",
       "      <td>-0.366484</td>\n",
       "      <td>0.746824</td>\n",
       "      <td>1.247538</td>\n",
       "      <td>-1.521214</td>\n",
       "      <td>1.343050</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150235</td>\n",
       "      <td>-0.382419</td>\n",
       "      <td>-0.304121</td>\n",
       "      <td>1.141382</td>\n",
       "      <td>-0.414432</td>\n",
       "      <td>-0.248223</td>\n",
       "      <td>1.065871</td>\n",
       "      <td>-0.729584</td>\n",
       "      <td>-3.064909</td>\n",
       "      <td>0.430729</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.627376</td>\n",
       "      <td>1.258283</td>\n",
       "      <td>-0.653569</td>\n",
       "      <td>-1.199824</td>\n",
       "      <td>-1.752736</td>\n",
       "      <td>-1.303956</td>\n",
       "      <td>-0.298844</td>\n",
       "      <td>0.772032</td>\n",
       "      <td>0.506764</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90111</td>\n",
       "      <td>1.347762</td>\n",
       "      <td>0.746815</td>\n",
       "      <td>0.362632</td>\n",
       "      <td>0.846772</td>\n",
       "      <td>-1.262384</td>\n",
       "      <td>1.364104</td>\n",
       "      <td>-0.075601</td>\n",
       "      <td>0.352371</td>\n",
       "      <td>-1.001628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.431206</td>\n",
       "      <td>1.143164</td>\n",
       "      <td>-0.381148</td>\n",
       "      <td>1.055597</td>\n",
       "      <td>-0.198674</td>\n",
       "      <td>-0.309390</td>\n",
       "      <td>0.105413</td>\n",
       "      <td>0.611066</td>\n",
       "      <td>0.372415</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      _id  feat_000  feat_001  feat_002  feat_003  feat_004  feat_005  \\\n",
       "0  112013  0.874623 -0.433386  1.282504  0.440211 -0.729979 -0.121770   \n",
       "1  107302  1.122571  0.275028 -0.296846  0.752930 -0.473619 -0.819199   \n",
       "2   10607 -0.246912 -0.004445  0.805970 -1.743573 -0.042794  1.096977   \n",
       "3  150235 -0.382419 -0.304121  1.141382 -0.414432 -0.248223  1.065871   \n",
       "4   90111  1.347762  0.746815  0.362632  0.846772 -1.262384  1.364104   \n",
       "\n",
       "   feat_006  feat_007  feat_008   ...    feat_991  feat_992  feat_993  \\\n",
       "0 -0.756523 -0.311089 -1.047285   ...    1.954668  1.426505  0.396491   \n",
       "1  0.022044 -2.374956  2.130340   ...    0.670175  0.168732 -1.674614   \n",
       "2 -0.054843 -0.661225  0.473623   ...   -0.371504  0.905834 -1.494369   \n",
       "3 -0.729584 -3.064909  0.430729   ...   -0.627376  1.258283 -0.653569   \n",
       "4 -0.075601  0.352371 -1.001628   ...    0.431206  1.143164 -0.381148   \n",
       "\n",
       "   feat_994  feat_995  feat_996  feat_997  feat_998  feat_999  target  \n",
       "0 -0.705992 -0.312878  1.045555 -2.495671  1.039028  2.045024       0  \n",
       "1  0.968680 -2.186223 -0.855602  0.118787 -0.765210 -0.077157       0  \n",
       "2 -0.157062 -0.366484  0.746824  1.247538 -1.521214  1.343050       0  \n",
       "3 -1.199824 -1.752736 -1.303956 -0.298844  0.772032  0.506764       1  \n",
       "4  1.055597 -0.198674 -0.309390  0.105413  0.611066  0.372415       0  \n",
       "\n",
       "[5 rows x 1002 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp_6506_bd_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = samp_6506_bd_df.iloc[:,1:-1]\n",
    "y = samp_6506_bd_df['target']\n",
    "\n",
    "skb_20 = SelectKBest(k=20)\n",
    "skb_20.fit(X, y)\n",
    "skb_20_feats = np.where(skb_20.get_support())[0]\n",
    "skb_20_cols = list(X[skb_20_feats].head().columns)\n",
    "\n",
    "skb_20_cols_new = sorted([int(x[-3:]) for x in skb_20_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_3_bd_samps</th>\n",
       "      <th>skb_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>257</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>269</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>308</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>315</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>336</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>341</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>395</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>504</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>526</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>639</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>681</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>701</td>\n",
       "      <td>724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>724</td>\n",
       "      <td>736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>736</td>\n",
       "      <td>769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>769</td>\n",
       "      <td>808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>808</td>\n",
       "      <td>823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>829</td>\n",
       "      <td>829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>867</td>\n",
       "      <td>849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>920</td>\n",
       "      <td>867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>956</td>\n",
       "      <td>920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    first_3_bd_samps  skb_20\n",
       "0                257     160\n",
       "1                269     257\n",
       "2                308     269\n",
       "3                315     315\n",
       "4                336     336\n",
       "5                341     341\n",
       "6                395     395\n",
       "7                504     490\n",
       "8                526     504\n",
       "9                639     681\n",
       "10               681     701\n",
       "11               701     724\n",
       "12               724     736\n",
       "13               736     769\n",
       "14               769     808\n",
       "15               808     823\n",
       "16               829     829\n",
       "17               867     849\n",
       "18               920     867\n",
       "19               956     920"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([sorted(first_3_bd_samps_correlated_feats_list), skb_20_cols_new], \\\n",
    "             index=['first_3_bd_samps','skb_20']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarks_df = pd.merge(ma_first_3_benchmark, ma_first_3_benchmark_6506, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_3_bd</th>\n",
       "      <th>first_3_bd_6506</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.685500</td>\n",
       "      <td>0.678600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_score</th>\n",
       "      <td>0.523333</td>\n",
       "      <td>0.518592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             first_3_bd  first_3_bd_6506\n",
       "train_score    0.685500         0.678600\n",
       "val_score      0.523333         0.518592"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmarks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skb_20_feats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.67820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_score</th>\n",
       "      <td>0.49668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             skb_20_feats\n",
       "train_score       0.67820\n",
       "val_score         0.49668"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma_skb_6506 = madelon_analyzer(samp_6506_bd_df[:5000], samp_6506_bd_df[5000:])\n",
    "ma_skb_benchmark_6506 = ma_skb_6506.train_val_scorer_df_maker(skb_20_cols_new,\\\n",
    "                                                                  'skb_20_feats')\n",
    "ma_skb_benchmark_6506"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skb_100_feats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.708800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_score</th>\n",
       "      <td>0.552457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             skb_100_feats\n",
       "train_score       0.708800\n",
       "val_score         0.552457"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skb_100 = SelectKBest(k=100)\n",
    "skb_100.fit(X, y)\n",
    "skb_100_feats = np.where(skb_100.get_support())[0]\n",
    "skb_100_cols = list(X[skb_100_feats].head().columns)\n",
    "skb_100_cols_new = sorted([int(x[-3:]) for x in skb_100_cols])\n",
    "ma_skb_100 = madelon_analyzer(samp_6506_bd_df[:5000], samp_6506_bd_df[5000:])\n",
    "ma_skb_100_scores = ma_skb_100.train_val_scorer_df_maker(skb_100_cols_new,\\\n",
    "                                                               'skb_100_feats')\n",
    "ma_skb_100_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sfm_feats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.857000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_score</th>\n",
       "      <td>0.762284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sfm_feats\n",
       "train_score   0.857000\n",
       "val_score     0.762284"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfm = SelectFromModel(LassoCV(), threshold='mean')\n",
    "sfm.fit(X, y)\n",
    "sfm_feats = np.where(sfm.get_support())[0]\n",
    "sfm_cols = list(X[sfm_feats].head().columns)\n",
    "sfm_ma = madelon_analyzer(samp_6506_bd_df[:5000], samp_6506_bd_df[5000:])\n",
    "ma_sfm_scores = sfm_ma.train_val_scorer_df_maker(sfm_cols, 'sfm_feats')\n",
    "ma_sfm_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_benchmark_feats = list(set((first_3_bd_samps_correlated_feats_list + skb_20_cols_new)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This shows that all 20 of the columns I selected are included in the top 100 seleced from \n",
    "benchmark_plus_skbtop100 = list(set(all_benchmark_feats + skb_100_cols_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>benchmark_plus_skbtop100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.712200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_score</th>\n",
       "      <td>0.538513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             benchmark_plus_skbtop100\n",
       "train_score                  0.712200\n",
       "val_score                    0.538513"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma_103 = madelon_analyzer(samp_6506_bd_df[:5000], samp_6506_bd_df[5000:])\n",
    "ma_103_scores = ma_103.train_val_scorer_df_maker(benchmark_plus_skbtop100, 'benchmark_plus_skbtop100')\n",
    "ma_103_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'benchmark_plus_skbtop100' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5d7b42ffb803>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeats_103\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feat_{:3}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbenchmark_plus_skbtop100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'benchmark_plus_skbtop100' is not defined"
     ]
    }
   ],
   "source": [
    "feats_103 = sorted(['feat_{:3}'.format(x) for x in benchmark_plus_skbtop100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_103 = \\\n",
    "'feat_004,feat_010,feat_061,feat_066,feat_078,feat_094,feat_100,feat_104,feat_107,feat_124,feat_139,feat_153,\\\n",
    "feat_154,feat_158,feat_160,feat_184,feat_188,feat_198,feat_229,feat_231,feat_245,feat_257,feat_263,feat_269,\\\n",
    "feat_276,feat_298,feat_304,feat_307,feat_308,feat_310,feat_314,feat_315,feat_316,feat_330,feat_336,feat_337,\\\n",
    "feat_341,feat_342,feat_344,feat_361,feat_368,feat_371,feat_380,feat_395,feat_396,feat_400,feat_413,feat_421,\\\n",
    "feat_426,feat_442,feat_449,feat_452,feat_470,feat_478,feat_487,feat_490,feat_496,feat_497,feat_504,feat_513,\\\n",
    "feat_526,feat_545,feat_553,feat_589,feat_595,feat_599,feat_638,feat_639,feat_660,feat_674,feat_681,feat_701,\\\n",
    "feat_710,feat_724,feat_736,feat_738,feat_769,feat_778,feat_781,feat_789,feat_808,feat_820,feat_823,feat_829,\\\n",
    "feat_830,feat_849,feat_862,feat_867,feat_885,feat_889,feat_895,feat_896,feat_898,feat_920,feat_941,feat_948,\\\n",
    "feat_954,feat_956,feat_969,feat_970,feat_977,feat_995,feat_996'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_103, cur_103 = con_cur_to_class_db()\n",
    "cur_103.execute(\"SELECT {}, target FROM madelon LIMIT 100000\".format(feats_103))\n",
    "results_103 = cur_103.fetchall()\n",
    "con_103.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_103_100000rows_df = pd.DataFrame(results_103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_004</th>\n",
       "      <th>feat_010</th>\n",
       "      <th>feat_061</th>\n",
       "      <th>feat_066</th>\n",
       "      <th>feat_078</th>\n",
       "      <th>feat_094</th>\n",
       "      <th>feat_100</th>\n",
       "      <th>feat_104</th>\n",
       "      <th>feat_107</th>\n",
       "      <th>feat_124</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_941</th>\n",
       "      <th>feat_948</th>\n",
       "      <th>feat_954</th>\n",
       "      <th>feat_956</th>\n",
       "      <th>feat_969</th>\n",
       "      <th>feat_970</th>\n",
       "      <th>feat_977</th>\n",
       "      <th>feat_995</th>\n",
       "      <th>feat_996</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.313364</td>\n",
       "      <td>-1.853105</td>\n",
       "      <td>-0.617570</td>\n",
       "      <td>1.213093</td>\n",
       "      <td>-1.691096</td>\n",
       "      <td>-0.823690</td>\n",
       "      <td>-0.527816</td>\n",
       "      <td>0.261401</td>\n",
       "      <td>-1.291643</td>\n",
       "      <td>0.006729</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.186616</td>\n",
       "      <td>1.307990</td>\n",
       "      <td>-0.191312</td>\n",
       "      <td>1.535919</td>\n",
       "      <td>-0.330030</td>\n",
       "      <td>1.385152</td>\n",
       "      <td>0.338486</td>\n",
       "      <td>-0.249347</td>\n",
       "      <td>-0.021732</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.252419</td>\n",
       "      <td>0.393065</td>\n",
       "      <td>0.146298</td>\n",
       "      <td>0.290831</td>\n",
       "      <td>1.717098</td>\n",
       "      <td>0.860437</td>\n",
       "      <td>0.548732</td>\n",
       "      <td>2.037863</td>\n",
       "      <td>0.933097</td>\n",
       "      <td>-0.994218</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.157805</td>\n",
       "      <td>-0.722995</td>\n",
       "      <td>1.135604</td>\n",
       "      <td>-0.672081</td>\n",
       "      <td>1.846824</td>\n",
       "      <td>0.874218</td>\n",
       "      <td>-0.924689</td>\n",
       "      <td>0.027623</td>\n",
       "      <td>-0.397976</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.891341</td>\n",
       "      <td>0.562609</td>\n",
       "      <td>1.943417</td>\n",
       "      <td>-0.387551</td>\n",
       "      <td>-0.180743</td>\n",
       "      <td>2.008322</td>\n",
       "      <td>0.004553</td>\n",
       "      <td>-1.010499</td>\n",
       "      <td>-0.810443</td>\n",
       "      <td>-1.123838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.675879</td>\n",
       "      <td>0.635782</td>\n",
       "      <td>0.453698</td>\n",
       "      <td>1.103762</td>\n",
       "      <td>-0.930680</td>\n",
       "      <td>-0.494260</td>\n",
       "      <td>1.046918</td>\n",
       "      <td>0.993074</td>\n",
       "      <td>-0.580654</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.458532</td>\n",
       "      <td>-0.589838</td>\n",
       "      <td>-0.372567</td>\n",
       "      <td>1.999407</td>\n",
       "      <td>0.855325</td>\n",
       "      <td>-0.335771</td>\n",
       "      <td>0.168373</td>\n",
       "      <td>-0.173113</td>\n",
       "      <td>-0.989014</td>\n",
       "      <td>0.227036</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081521</td>\n",
       "      <td>-0.965682</td>\n",
       "      <td>-0.319073</td>\n",
       "      <td>-0.574551</td>\n",
       "      <td>2.671121</td>\n",
       "      <td>-0.479038</td>\n",
       "      <td>-0.552304</td>\n",
       "      <td>0.977553</td>\n",
       "      <td>0.286620</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.621189</td>\n",
       "      <td>2.448886</td>\n",
       "      <td>0.379100</td>\n",
       "      <td>0.581095</td>\n",
       "      <td>0.373658</td>\n",
       "      <td>0.007197</td>\n",
       "      <td>-1.526137</td>\n",
       "      <td>0.484845</td>\n",
       "      <td>-1.108698</td>\n",
       "      <td>-0.640530</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.188028</td>\n",
       "      <td>-0.598852</td>\n",
       "      <td>-0.139465</td>\n",
       "      <td>1.913404</td>\n",
       "      <td>0.216031</td>\n",
       "      <td>-0.209423</td>\n",
       "      <td>0.921488</td>\n",
       "      <td>0.773503</td>\n",
       "      <td>-1.985925</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feat_004  feat_010  feat_061  feat_066  feat_078  feat_094  feat_100  \\\n",
       "0 -0.313364 -1.853105 -0.617570  1.213093 -1.691096 -0.823690 -0.527816   \n",
       "1 -0.252419  0.393065  0.146298  0.290831  1.717098  0.860437  0.548732   \n",
       "2 -1.891341  0.562609  1.943417 -0.387551 -0.180743  2.008322  0.004553   \n",
       "3 -2.458532 -0.589838 -0.372567  1.999407  0.855325 -0.335771  0.168373   \n",
       "4  0.621189  2.448886  0.379100  0.581095  0.373658  0.007197 -1.526137   \n",
       "\n",
       "   feat_104  feat_107  feat_124   ...    feat_941  feat_948  feat_954  \\\n",
       "0  0.261401 -1.291643  0.006729   ...   -2.186616  1.307990 -0.191312   \n",
       "1  2.037863  0.933097 -0.994218   ...   -1.157805 -0.722995  1.135604   \n",
       "2 -1.010499 -0.810443 -1.123838   ...    0.675879  0.635782  0.453698   \n",
       "3 -0.173113 -0.989014  0.227036   ...   -0.081521 -0.965682 -0.319073   \n",
       "4  0.484845 -1.108698 -0.640530   ...   -0.188028 -0.598852 -0.139465   \n",
       "\n",
       "   feat_956  feat_969  feat_970  feat_977  feat_995  feat_996  target  \n",
       "0  1.535919 -0.330030  1.385152  0.338486 -0.249347 -0.021732       0  \n",
       "1 -0.672081  1.846824  0.874218 -0.924689  0.027623 -0.397976       0  \n",
       "2  1.103762 -0.930680 -0.494260  1.046918  0.993074 -0.580654       0  \n",
       "3 -0.574551  2.671121 -0.479038 -0.552304  0.977553  0.286620       1  \n",
       "4  1.913404  0.216031 -0.209423  0.921488  0.773503 -1.985925       1  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_103_100000rows_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-646469780bb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0msfm_103_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_103\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msfm_103_ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmadelon_analyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_103_all_rows_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamp_6506_bd_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mma_sfm_103_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msfm_103_ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_val_scorer_df_maker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msfm_103_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sfm103_feats_100000rows'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mma_sfm_103_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ga-dsi/projects/project_3/madelon_analyzer.py\u001b[0m in \u001b[0;36mtrain_val_scorer_df_maker\u001b[0;34m(self, features, name, model, params)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mgridsearch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mgridsearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgridsearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    636\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    637\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 638\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36m_handle_tasks\u001b[0;34m(taskqueue, put, outqueue, pool, cache)\u001b[0m\n\u001b[1;32m    422\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m                         \u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m                         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    369\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                 \u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                 \u001b[0mCustomizablePickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reducers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, a)\u001b[0m\n\u001b[1;32m    238\u001b[0m                     print(\"Memmaping (shape=%r, dtype=%s) to new file %s\" % (\n\u001b[1;32m    239\u001b[0m                         a.shape, a.dtype, filename))\n\u001b[0;32m--> 240\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mdumped_filename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m                     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdumped_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFILE_PERMISSIONS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(value, filename, compress, protocol, cache_size)\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_filename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             \u001b[0mNumpyPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0mNumpyPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/pickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_framing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTOP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_framing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;31m# And then array bytes are written right after the wrapper.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mwrite_array\u001b[0;34m(self, array, pickler)\u001b[0m\n\u001b[1;32m     91\u001b[0m                                            \u001b[0mbuffersize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffersize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                                            order=self.order):\n\u001b[0;32m---> 93\u001b[0;31m                 \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_handle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "X_103 = results_103_all_rows_df.T[:-1].T\n",
    "y_103 = results_103_all_rows_df.T[-1:].T\n",
    "\n",
    "sfm_103 = SelectFromModel(LassoCV(), threshold='mean')\n",
    "sfm_103.fit(X_103, y_103)\n",
    "sfm_103_feats = np.where(sfm_103.get_support())[0]\n",
    "sfm_103_cols = list(X_103.head(1).columns)\n",
    "sfm_103_ma = madelon_analyzer(results_103_all_rows_df, samp_6506_bd_df)\n",
    "ma_sfm_103_scores = sfm_103_ma.train_val_scorer_df_maker(sfm_103_cols, 'sfm103_feats_100000rows')\n",
    "ma_sfm_103_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sfm2_feats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.699000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_score</th>\n",
       "      <td>0.508632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sfm2_feats\n",
       "train_score    0.699000\n",
       "val_score      0.508632"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfm2 = SelectFromModel(LassoCV(), threshold='mean')\n",
    "sfm2.fit(X[all_benchmark_feats], y)\n",
    "sfm2_feats = np.where(sfm2.get_support())[0]\n",
    "sfm2_cols = list(X[sfm2_feats].head().columns)\n",
    "sfm2_ma = madelon_analyzer(samp_6506_bd_df[:5000], samp_6506_bd_df[5000:])\n",
    "ma_sfm2_scores = sfm2_ma.train_val_scorer_df_maker(sfm2_cols, 'sfm2_feats')\n",
    "ma_sfm2_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarks_df = pd.merge(ma_first_3_benchmark, ma_first_3_benchmark_6506, left_index=True, right_index=True)\n",
    "benchmarks_df = pd.merge(benchmarks_df, ma_skb_benchmark_6506, left_index=True, right_index=True)\n",
    "benchmarks_df = pd.merge(benchmarks_df, ma_sfm_scores, left_index=True, right_index=True)\n",
    "benchmarks_df = pd.merge(benchmarks_df, ma_sfm2_scores, left_index=True, right_index=True)\n",
    "benchmarks_df = pd.merge(benchmarks_df, ma_skb_100_scores, left_index=True, right_index=True)\n",
    "benchmarks_df = pd.merge(benchmarks_df, ma_103_scores, left_index=True, right_index=True)\n",
    "multi_benchmarks_df = benchmarks_df.T.sort_values('val_score', ascending=False)\n",
    "multi_benchmarks_df['description'] = ['Top 5 using SelectFromModel with LassoCV, threshold=mean', \n",
    "                                     'Top 100 using SelectKBest', 'SKB top 100 plus top 20',\n",
    "                                      'Top 20 from the small samples', \n",
    "                                     'Using the same list from Top 20 from the small samples but on representitive sized sample',\n",
    "                                     'SFM, on only the top 20 from small samples features', 'SKB top 20']\n",
    "pd.to_pickle(multi_benchmarks_df, 'Data/multi_benchmarks_df.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_score</th>\n",
       "      <th>val_score</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sfm_feats</th>\n",
       "      <td>0.8570</td>\n",
       "      <td>0.762284</td>\n",
       "      <td>Top 5 using SelectFromModel with LassoCV, thre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skb_100_feats</th>\n",
       "      <td>0.7088</td>\n",
       "      <td>0.552457</td>\n",
       "      <td>Top 100 using SelectKBest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>benchmark_plus_skbtop100</th>\n",
       "      <td>0.7122</td>\n",
       "      <td>0.538513</td>\n",
       "      <td>SKB top 100 plus top 20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_3_bd</th>\n",
       "      <td>0.6855</td>\n",
       "      <td>0.523333</td>\n",
       "      <td>Top 20 from the small samples</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_3_bd_6506</th>\n",
       "      <td>0.6786</td>\n",
       "      <td>0.518592</td>\n",
       "      <td>Using the same list from Top 20 from the small...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sfm2_feats</th>\n",
       "      <td>0.6990</td>\n",
       "      <td>0.508632</td>\n",
       "      <td>SFM, on only the top 20 from small samples fea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skb_20_feats</th>\n",
       "      <td>0.6782</td>\n",
       "      <td>0.496680</td>\n",
       "      <td>SKB top 20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          train_score  val_score  \\\n",
       "sfm_feats                      0.8570   0.762284   \n",
       "skb_100_feats                  0.7088   0.552457   \n",
       "benchmark_plus_skbtop100       0.7122   0.538513   \n",
       "first_3_bd                     0.6855   0.523333   \n",
       "first_3_bd_6506                0.6786   0.518592   \n",
       "sfm2_feats                     0.6990   0.508632   \n",
       "skb_20_feats                   0.6782   0.496680   \n",
       "\n",
       "                                                                description  \n",
       "sfm_feats                 Top 5 using SelectFromModel with LassoCV, thre...  \n",
       "skb_100_feats                                     Top 100 using SelectKBest  \n",
       "benchmark_plus_skbtop100                            SKB top 100 plus top 20  \n",
       "first_3_bd                                    Top 20 from the small samples  \n",
       "first_3_bd_6506           Using the same list from Top 20 from the small...  \n",
       "sfm2_feats                SFM, on only the top 20 from small samples fea...  \n",
       "skb_20_feats                                                     SKB top 20  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_pickle(multi_benchmarks_df, 'Data/multi_benchmarks_df.p')\n",
    "multi_benchmarks_df = pd.read_pickle('Data/multi_benchmarks_df.p')\n",
    "multi_benchmarks_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thoughts after benchmarking and initial feature selection\n",
    "\n",
    "Using a naive KNeighborsClassifier, I was able to score a 0.762284 for my validation set. From three random 1% samples of the data, I was able to identify 20 colinear features, which scored 0.518592 when I validated it on a random sample of 6506 rows, which is a representative sample of the population with a 90% confidence level and a 1% margin of error. \n",
    "\n",
    "Using SelectKBest to get 100 features, I was able to score higher on my validation set than when I looked for 20 features. This tells me that I was probably missing some of the important features in the set of 20 using this method. Although, I descovered that my benchmark list of 20 included 3 features that were not in the SKB top 100 list. So I added them, and will be using that full list.\n",
    "\n",
    "Moving forward, I'm going to play with these lists to see if I can get a higher score than the 5 features from SelectFromModel.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = samp_3000_bd_df.T[1:].T\n",
    "train_df = samp_6506_bd_df.T[1:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.35 s, sys: 90 ms, total: 2.44 s\n",
      "Wall time: 12.4 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SFM top 5 features, RFC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_score</th>\n",
       "      <td>0.763333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             SFM top 5 features, RFC\n",
       "train_score                 1.000000\n",
       "val_score                   0.763333"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_params = {\n",
    "    'n_estimators':[10,50,100,200],\n",
    "    'max_features':['auto','log2'],\n",
    "}\n",
    "\n",
    "ma_fi = madelon_analyzer(train_df, val_df)\n",
    "%time ma_fi_scores_5 = ma_fi.train_val_scorer_df_maker(sfm_cols, 'SFM top 5 features, RFC',\\\n",
    "                                                     RandomForestClassifier, rf_params)\n",
    "ma_fi_scores_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.7 s, sys: 110 ms, total: 11.8 s\n",
      "Wall time: 41.1 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>103 features, RFC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_score</th>\n",
       "      <td>0.759667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             103 features, RFC\n",
       "train_score           1.000000\n",
       "val_score             0.759667"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_params = {\n",
    "    'n_estimators':[10,50,100,200],\n",
    "    'max_features':['auto','log2'],\n",
    "}\n",
    "\n",
    "ma_fi = madelon_analyzer(train_df, val_df)\n",
    "%time ma_fi_scores_103 = ma_fi.train_val_scorer_df_maker(benchmark_plus_skbtop100, '103 features, RFC',\\\n",
    "                                                     RandomForestClassifier, rf_params)\n",
    "ma_fi_scores_103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbparams = {\n",
    "    'learning_rate': [0.1,0.5,1], \n",
    "    'n_estimators': [100,200], \n",
    "    'max_depth': [2,4], \n",
    "}\n",
    "\n",
    "ma_gb = madelon_analyzer(train_df, val_df)\n",
    "%time ma_gb_scores_103 = ma_fi.train_val_scorer_df_maker(benchmark_plus_skbtop100, '103 features, GBC',\\\n",
    "                                                     GradientBoostingClassifier, gbparams)\n",
    "ma_gb_scores_103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    " \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UCI Web Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning file paths to variables. \n",
    "\n",
    "train_data_uci_madelon = './web_madelon_data/madelon_train.data.txt'\n",
    "train_label_uci_madelon = './web_madelon_data/madelon_train.labels.txt'\n",
    "\n",
    "val_data_uci_madelon = './web_madelon_data/madelon_valid.data.txt'\n",
    "val_label_uci_madelon = './web_madelon_data/madelon_valid.labels.txt'\n",
    "\n",
    "test_data_uci_madelon = './web_madelon_data/madelon_test.data.txt'\n",
    "\n",
    "params_uci_madelon = './web_madelon_data/madelon.param.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframes for the train, test, and val datasets.\n",
    "\n",
    "train_uci_df = pd.read_csv(train_data_uci_madelon, delimiter=' ', header=None).drop(500, axis=1)\n",
    "test_uci_df = pd.read_csv(test_data_uci_madelon, delimiter=' ', header=None).drop(500, axis=1)\n",
    "val_uci_df = pd.read_csv(val_data_uci_madelon, delimiter=' ', header=None).drop(500, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4400\n",
      "600\n",
      "2000\n",
      "1800\n"
     ]
    }
   ],
   "source": [
    "# Checking to make sure I have the right amount of rows.\n",
    "\n",
    "print(len(val_uci_df) + len(train_uci_df) + len(test_uci_df))\n",
    "print(len(val_uci_df))\n",
    "print(len(train_uci_df))\n",
    "print(len(test_uci_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating column names for all of the uci dataframes.\n",
    "\n",
    "feature_col_names = ['feat_{}'.format(i) for i in range(0,500)]\n",
    "\n",
    "train_uci_df.columns = feature_col_names\n",
    "test_uci_df.columns = feature_col_names\n",
    "val_uci_df.columns = feature_col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_csv(train_label_uci_madelon, header=None)\n",
    "y_val = pd.read_csv(val_label_uci_madelon, header=None)\n",
    "\n",
    "y_train.columns = ['target']\n",
    "y_val.columns = ['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_uci_df = pd.merge(train_uci_df, y_train, left_index=True, right_index=True)\n",
    "val_uci_df = pd.merge(val_uci_df, y_val, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_uci_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating my three training sets that are 10% of the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_train_uci_10 = train_uci_df.sample(int(len(train_uci_df)*0.1), random_state=1)\n",
    "s2_train_uci_10 = train_uci_df.sample(int(len(train_uci_df)*0.1), random_state=10)\n",
    "s3_train_uci_10 = train_uci_df.sample(int(len(train_uci_df)*0.1), random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_train_uci_10.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_dtree_mean_scores = []\n",
    "for col in s1_train_uci_10.drop('target', axis=1).columns:\n",
    "    s1_dtree_mean_scores.append(mean_r2_for_feature(s1_train_uci_10.drop('target', axis=1), col, DecisionTreeRegressor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_dtree_score_df = pd.DataFrame([s1_dtree_mean_scores, feature_col_names]).T.sort_values(0, ascending=False)\n",
    "s1_dtree_score_df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_correlated_cols = list(s1_dtree_score_df.head(20).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the above calculation, I have exactly 20 features that have positive scores. There is 5 predictors and 15 linear\n",
    "    # combinations, so I think I've identified my noise! Next, I'm going to do this for the other random 10% samples\n",
    "    # and compare the results. Maybe keep the top 20 of all three for my next step, using lass/ridge/elastic net to\n",
    "    # remove features that are redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_dtree_mean_scores = []\n",
    "for col in s2_train_uci_10.drop('target', axis=1).columns:\n",
    "    s2_dtree_mean_scores.append(mean_r2_for_feature(s2_train_uci_10.drop('target', axis=1), col, DecisionTreeRegressor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_dtree_score_df = pd.DataFrame([s2_dtree_mean_scores, feature_col_names]).T.sort_values(0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_correlated_cols = list(s2_dtree_score_df.head(20).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_dtree_mean_scores = []\n",
    "for col in s3_train_uci_10.drop('target', axis=1).columns:\n",
    "    s3_dtree_mean_scores.append(mean_r2_for_feature(s3_train_uci_10.drop('target', axis=1), col, DecisionTreeRegressor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_dtree_score_df = pd.DataFrame([s3_dtree_mean_scores, feature_col_names]).T.sort_values(0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_correlated_cols = list(s3_dtree_score_df.head(20).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added all of my top 20 columns for the 3 random 10% samples to see if there was variation, and they all got the exact\n",
    "    # same features. This is a good sign!\n",
    "\n",
    "len(set(s1_correlated_cols+s2_correlated_cols+s3_correlated_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_correlated_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_all_results_df = pd.DataFrame([s1_correlated_cols, s2_correlated_cols, s3_correlated_cols]).T\n",
    "s_all_results_df.columns = ['sample_1', 'sample_2', 'sample_3']\n",
    "s_all_results_df.sort('sample_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_corr = s1_train_uci_10[s1_correlated_cols].corr()\n",
    "s2_corr = s2_train_uci_10[s2_correlated_cols].corr()\n",
    "s3_corr = s3_train_uci_10[s3_correlated_cols].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_corr_desc = s1_corr.describe().T\n",
    "s1_corr_desc['mean'] = abs(s1_corr_desc['mean'].values)\n",
    "s1_corr_desc = s1_corr_desc.sort_values('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_corr_desc = s2_corr.describe().T\n",
    "s2_corr_desc['mean'] = abs(s2_corr_desc['mean'].values)\n",
    "s2_corr_desc = s2_corr_desc.sort_values('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_corr_desc = s1_corr.describe().T\n",
    "s3_corr_desc['mean'] = abs(s3_corr_desc['mean'].values)\n",
    "s3_corr_desc = s3_corr_desc.sort_values('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_skb_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_corr_desc[['mean']][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_corr_cols = list(set(list(s1_corr_desc.head(7).index)+list(s2_corr_desc.head(7).index)+list(s3_corr_desc.head(7).index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_corr_corr = s2_train_uci_10[low_corr_cols].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "\n",
    "corr = s1_corr\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I realized this might not be a good method for finding redundant features. Leaving here in case I use it later.\n",
    "s1_redundant_feats = list(set([433,153,128,472,28,451,318,281,433,475,241,28,451,48,378,453,493,64,336,128,105]))\n",
    "len(s1_redundant_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the target values associated with each sample set.\n",
    "\n",
    "s1_train_uci_10_with_y = train_uci_df.sample(int(len(train_uci_df)*0.1), random_state=1)\n",
    "\n",
    "s2_train_uci_10_with_y = train_uci_df.sample(int(len(train_uci_df)*0.1), random_state=10)\n",
    "\n",
    "s3_train_uci_10_with_y = train_uci_df.sample(int(len(train_uci_df)*0.1), random_state=100)\n",
    "\n",
    "y_s1 = s1_train_uci_10_with_y[s1_correlated_cols+[-1]]['target']\n",
    "\n",
    "y_s2 = s2_train_uci_10_with_y[s2_correlated_cols+[-1]]['target']\n",
    "\n",
    "y_s3 = s3_train_uci_10_with_y[s3_correlated_cols+[-1]]['target']\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest \n",
    "\n",
    "# results f-classif: ['feat_241', 'feat_475', 'feat_64', 'feat_128', 'feat_336']\n",
    "skb_s1 = SelectKBest(k=5)\n",
    "skb_s1.fit(s1_train_uci_10[s1_correlated_cols], y_s1)\n",
    "s1_skb_feats = np.where(skb_s1.get_support())[0]\n",
    "s1_skb_cols = list(s1_train_uci_10[s1_correlated_cols][s1_skb_feats].head().columns)\n",
    "\n",
    "s1_skb_cols\n",
    "\n",
    "# results f-classif: ['feat_48', 'feat_475', 'feat_378', 'feat_241', 'feat_128']\n",
    "\n",
    "skb_s2 = SelectKBest(k=5)\n",
    "skb_s2.fit(s2_train_uci_10[s2_correlated_cols], y_s2)\n",
    "s2_skb_feats = np.where(skb_s2.get_support())[0]\n",
    "s2_skb_cols = list(s2_train_uci_10[s2_correlated_cols][s2_skb_feats].head().columns)\n",
    "\n",
    "s2_skb_cols\n",
    "\n",
    "# results f-classif: ['feat_241', 'feat_128', 'feat_378', 'feat_475', 'feat_338']\n",
    "\n",
    "skb_s3 = SelectKBest(k=5)\n",
    "skb_s3.fit(s3_train_uci_10[s3_correlated_cols], y_s3)\n",
    "s3_skb_feats = np.where(skb_s3.get_support())[0]\n",
    "s3_skb_cols = list(s3_train_uci_10[s3_correlated_cols][s3_skb_feats].head().columns)\n",
    "\n",
    "s3_skb_cols\n",
    "\n",
    "# Features that show in all three of the SelectKBest fits: 128, 241, 475\n",
    "# Features that show twice: 378\n",
    "# Features that show once: 64, 48, 338, 336\n",
    "\n",
    "skb_all_samp_feats = set(s1_skb_cols + s2_skb_cols + s3_skb_cols)\n",
    "skb_all_samp_feats\n",
    "\n",
    "from sklearn.linear_model import Lasso, ElasticNet\n",
    "\n",
    "# Found with Lasso: ['feat_442', 'feat_378', 'feat_475', 'feat_105', 'feat_336']\n",
    "# Found with ElasticNet: ['feat_153','feat_442','feat_241','feat_378','feat_453','feat_105','feat_336','feat_455']\n",
    "    \n",
    "sfm_s1 = SelectFromModel(ElasticNet(), threshold='mean')\n",
    "sfm_s1.fit(s1_train_uci_10[s1_correlated_cols], y_s1)\n",
    "s1_sfm_feats = np.where(sfm_s1.get_support())[0]\n",
    "s1_sfm_cols = list(s1_train_uci_10[s1_correlated_cols][s1_sfm_feats].head().columns)\n",
    "s1_sfm_cols\n",
    "\n",
    "# Found with Lasso: ['feat_475', 'feat_453', 'feat_64']\n",
    "# Found with ElasticNet: ['feat_475', 'feat_336', 'feat_241', 'feat_64', 'feat_472']\n",
    "\n",
    "sfm_s2 = SelectFromModel(ElasticNet(), threshold='mean')\n",
    "sfm_s2.fit(s1_train_uci_10[s2_correlated_cols], y_s2)\n",
    "s2_sfm_feats = np.where(sfm_s2.get_support())[0]\n",
    "s2_sfm_cols = list(s2_train_uci_10[s2_correlated_cols][s2_sfm_feats].head().columns)\n",
    "s2_sfm_cols\n",
    "\n",
    "# Found with Lasso: ['feat_318', 'feat_378', 'feat_475', 'feat_338']\n",
    "# Found with ElasticNet: ['feat_241','feat_318','feat_493','feat_378','feat_475','feat_455','feat_338']\n",
    "\n",
    "sfm_s3 = SelectFromModel(ElasticNet(), threshold='mean')\n",
    "sfm_s3.fit(s3_train_uci_10[s3_correlated_cols], y_s3)\n",
    "s3_sfm_feats = np.where(sfm_s3.get_support())[0]\n",
    "s3_sfm_cols = list(s3_train_uci_10[s3_correlated_cols][s3_sfm_feats].head().columns)\n",
    "s3_sfm_cols\n",
    "\n",
    "# Features that show in all three of the SelectFromModel fits: 475\n",
    "# Features that show twice: 378\n",
    "# Features that show once: 64, 105, 318, 336, 338, 442, 453\n",
    "\n",
    "sfm_all_samp_feats = sorted(list(set(s1_sfm_cols + s2_sfm_cols + s3_sfm_cols)))\n",
    "sfm_all_samp_feats\n",
    "\n",
    "# Features that appear in both SFM and SKB: 64, 336, 338, 378, 475\n",
    "# I feel like I should also consider 128 and 241 because that appeared in all three sample sets for SKB.\n",
    "\n",
    "sfm_skb_all_feats_combo = set(list(skb_all_samp_feats) + list(sfm_all_samp_feats))\n",
    "sfm_skb_all_feats_combo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Initial thoughts:\n",
    "\n",
    "#### UCI Web Data\n",
    "\n",
    "Using the unsupervised learning technique where a regressor is used to compare every feature (column) against the rest of the dataset, I was able to find exactly 20 features that have mean R^2 scores that are positive, and most of them are very high (in the 0.8-0.9 range) for all three of the random data subsets. Since 480/500 of the features in the madelon dataset are noise, I believe that this is a good indication that I have found my 5 predictor features and the 15 linear combinations.\n",
    "\n",
    "Using SelectKBest with k=5 on my 3 random data subsets, I was able to identify 8 unique features. Using SelectFromModel with the Lasso estimator, I was able to identify 9. Between these two lists of features, only 5 are the same. SelectFromModel returned 5 for the first dataset, 3 for the second, and 4 for the third. Since the full dataset has five important features, I think that the first sample is the most representative of the data. \n",
    "\n",
    "Moving forward, I will use GridSearchCV to tune my model hyperparameters and try various combonations of the important features I identified, starting with the 5 features that I found in both my SFM and SKB models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
