{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import psycopg2 as pg2\n",
    "from psycopg2.extras import RealDictCursor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit, StratifiedShuffleSplit, \\\n",
    "                                    train_test_split, StratifiedKFold, KFold\n",
    "    \n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, LogisticRegression, \\\n",
    "                                 LogisticRegressionCV, LassoCV, \\\n",
    "                                 ElasticNetCV, RidgeCV\n",
    "        \n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, \\\n",
    "                                      SelectFromModel, \\\n",
    "                                      RFE, SelectPercentile, \\\n",
    "                                      f_regression\n",
    "            \n",
    "from sklearn.pipeline import Pipeline\n",
    "from IPython.display import display\n",
    "from itertools import combinations\n",
    "\n",
    "# Assigning file paths to variables. \n",
    "train_data_uci_madelon = './web_madelon_data/madelon_train.data.txt'\n",
    "train_label_uci_madelon = './web_madelon_data/madelon_train.labels.txt'\n",
    "val_data_uci_madelon = './web_madelon_data/madelon_valid.data.txt'\n",
    "val_label_uci_madelon = './web_madelon_data/madelon_valid.labels.txt'\n",
    "test_data_uci_madelon = './web_madelon_data/madelon_test.data.txt'\n",
    "params_uci_madelon = './web_madelon_data/madelon.param.txt'\n",
    "\n",
    "\n",
    "# Creating dataframes for the train, test, and val datasets.\n",
    "train_uci_df = pd.read_csv(train_data_uci_madelon, delimiter=' ', header=None).drop(500, axis=1)\n",
    "test_uci_df = pd.read_csv(test_data_uci_madelon, delimiter=' ', header=None).drop(500, axis=1)\n",
    "val_uci_df = pd.read_csv(val_data_uci_madelon, delimiter=' ', header=None).drop(500, axis=1)\n",
    "\n",
    "\n",
    "# Creating column names for all of the uci dataframes.\n",
    "feature_col_names = ['feat_{}'.format(i) for i in range(0,500)]\n",
    "train_uci_df.columns = feature_col_names\n",
    "test_uci_df.columns = feature_col_names\n",
    "val_uci_df.columns = feature_col_names\n",
    "\n",
    "\n",
    "y_train = pd.read_csv(train_label_uci_madelon, header=None)\n",
    "y_val = pd.read_csv(val_label_uci_madelon, header=None)\n",
    "\n",
    "y_train.columns = ['target']\n",
    "y_val.columns = ['target']\n",
    "\n",
    "\n",
    "# Final DataFrames with labels\n",
    "train_uci_df = pd.merge(train_uci_df, y_train, left_index=True, right_index=True)\n",
    "val_uci_df = pd.merge(val_uci_df, y_val, left_index=True, right_index=True)\n",
    "\n",
    "# 20 Columns (5 important, 15 redundant)\n",
    "top_20_real_features = sorted([153,442,318,433,241,28,378,475,48,472,451,493,453,281,64,128,105,336,338,455])\n",
    "top_12_real_features = [48,64,105,128,241,318,336,338,378,442,453,475]\n",
    "top_7_real_features = [64, 128, 241, 336, 338, 378, 475]\n",
    "top_5_real_features = [64, 336, 338, 378, 475]\n",
    "top_14_elasticnet_real_features = [64,105,153,241,318,336,338,378,442,453,455,472,475,493]\n",
    "\n",
    "all_feat_lists = [top_20_real_features, top_12_real_features, top_7_real_features, top_5_real_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using GridSearchCV to fit my model with a ttsplit of the training data\n",
    "\n",
    "results = {}\n",
    "all_feat_list_names = \\\n",
    "['top_20_real_features', 'top_12_real_features', 'top_7_real_features', 'top_5_real_features']\n",
    "\n",
    "\n",
    "for i, feat_list in enumerate(all_feat_lists):\n",
    "\n",
    "    knc_params = {\n",
    "    'n_neighbors':range(1,100,2)\n",
    "    }\n",
    "\n",
    "    y = train_uci_df['target']\n",
    "    X = train_uci_df[feat_list]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    knc_gs = GridSearchCV(KNeighborsClassifier(), param_grid=knc_params, cv=5, n_jobs=-1)\n",
    "    knc_gs.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    train_score = knc_gs.score(X_train_scaled, y_train)\n",
    "    test_score = knc_gs.score(X_test_scaled, y_test)\n",
    "    \n",
    "    results[all_feat_list_names[i]] = {'train_score':train_score, 'test_score':test_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tt_split_scores_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using GridSearchCV to fit my model with all the training data and using the validation data\n",
    "\n",
    "results = {}\n",
    "all_feat_list_names = \\\n",
    "['top_20_real_features', 'top_12_real_features', 'top_7_real_features', 'top_5_real_features']\n",
    "\n",
    "\n",
    "for i, feat_list in enumerate(all_feat_lists):\n",
    "\n",
    "    knc_params = {\n",
    "    'n_neighbors':range(1,50,2)\n",
    "    }\n",
    "\n",
    "    y_train = train_uci_df['target']\n",
    "    X_train = train_uci_df[feat_list]\n",
    "    y_val = val_uci_df['target']\n",
    "    X_val = val_uci_df[feat_list]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    knc_gs = GridSearchCV(KNeighborsClassifier(), param_grid=knc_params, cv=5, n_jobs=-1)\n",
    "    knc_gs.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    train_score = knc_gs.score(X_train_scaled, y_train)\n",
    "    val_score = knc_gs.score(X_val_scaled, y_val)\n",
    "    \n",
    "    results[all_feat_list_names[i]] = {'train_score':train_score, 'val_score':val_score, }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knc_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_scores_df = pd.DataFrame(results)\n",
    "train_val_scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV, initial impressions:\n",
    "\n",
    "Based off of my gridsearch results, I'm scoring the best with all 20 features. This means that my SelectKBest, and SelectFromModel recommendations are not accurate. I need to go back and tune those more.\n",
    "\n",
    "Alternatively, I should iterate through a list of all of the 20 features and graph the results. Theoretically, every time I have a dip in my model score, I've elemenated an important feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_list = [1,2,3,4,5,6,7,8,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffled_list = shuffle(a_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffled_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_val_scorer_df_maker_KNNC(features, name):\n",
    "    results = {}\n",
    "\n",
    "    knc_params = {\n",
    "    'n_neighbors':range(1,50,2)\n",
    "    }\n",
    "\n",
    "    y_train = train_uci_df['target']\n",
    "    X_train = train_uci_df[features]\n",
    "    y_val = val_uci_df['target']\n",
    "    X_val = val_uci_df[features]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    knc_gs = GridSearchCV(KNeighborsClassifier(), param_grid=knc_params, cv=5, n_jobs=-1)\n",
    "    knc_gs.fit(X_train_scaled, y_train)\n",
    "\n",
    "    train_score = knc_gs.score(X_train_scaled, y_train)\n",
    "    val_score = knc_gs.score(X_val_scaled, y_val)\n",
    "    \n",
    "    results[name] = {'train_score':train_score, 'val_score':val_score}\n",
    "    \n",
    "    score_df = pd.DataFrame(results)\n",
    "    return score_df\n",
    "    \n",
    "def plot_top_down_feature_elination_scores(features, random=False, reverse=False, noise=False):\n",
    "    \n",
    "    if random:\n",
    "        shuffle(features)\n",
    "        all_feats = features\n",
    "        reverse_all_feats = list(reversed(all_feats))\n",
    "\n",
    "    else:\n",
    "        if reverse:\n",
    "            all_feats = sorted(features, reverse=True)\n",
    "            reverse_all_feats = sorted(features)\n",
    "        else:\n",
    "            all_feats = sorted(features)\n",
    "            reverse_all_feats = sorted(features, reverse=True)\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for i in range(len(all_feats)):\n",
    "\n",
    "        knc_params = {\n",
    "        'n_neighbors':range(3,26,2)\n",
    "        }\n",
    "\n",
    "        y_train = train_uci_df['target']\n",
    "        X_train = train_uci_df[all_feats]\n",
    "        y_val = val_uci_df['target']\n",
    "        X_val = val_uci_df[all_feats]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "        knc_gs = GridSearchCV(KNeighborsClassifier(), param_grid=knc_params, cv=5, n_jobs=-1)\n",
    "        knc_gs.fit(X_train_scaled, y_train)\n",
    "\n",
    "        train_score = knc_gs.score(X_train_scaled, y_train)\n",
    "        val_score = knc_gs.score(X_val_scaled, y_val)\n",
    "\n",
    "        results[i] = {'train_score':train_score, 'val_score':val_score}\n",
    "\n",
    "        all_feats = all_feats[:-1]\n",
    "\n",
    "    results_df = pd.DataFrame(results).T\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.plot(results_df)\n",
    "    plt.xlabel('Number of features removed from list')\n",
    "    plt.ylabel('kNN model score')\n",
    "    _ = plt.xticks(range(len(features)))\n",
    "    _ = plt.title('KNN model scores from top-down feature removal (all_dipped_feats reversed)')\n",
    "\n",
    "    select_feats = []\n",
    "    \n",
    "    for ind,x in enumerate(results_df['val_score']):\n",
    "        \n",
    "        if noise:\n",
    "            if ind != 0 and results_df['val_score'][ind] > results_df['val_score'][ind-1]:\n",
    "                plt.plot(ind, results_df['val_score'][ind], 'o', color='b', label='feat_{}'.format(reverse_all_feats[ind-1]))\n",
    "                select_feats.append(reverse_all_feats[ind-1])\n",
    "        else:\n",
    "            if ind != 0 and results_df['val_score'][ind] < results_df['val_score'][ind-1]:\n",
    "                plt.plot(ind, results_df['val_score'][ind], 'o', color='r', label='feat_{}'.format(reverse_all_feats[ind-1]))\n",
    "                select_feats.append(reverse_all_feats[ind-1])\n",
    "            \n",
    "    _ = plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return results_df, select_feats\n",
    "\n",
    "def list_top_dipped_feats(features, noise=False, random=False):\n",
    "    \n",
    "    if random:\n",
    "        if noise:\n",
    "            results_df_1, select_feats_1 = plot_top_down_feature_elination_scores(features, random=True, noise=True)\n",
    "            results_df_2, select_feats_2 = plot_top_down_feature_elination_scores(features, random=True, noise=True)\n",
    "            print(\"TOP RANDOMIZED NOISE FEATURES:\", sorted(list(set(select_feats_1[:5]+select_feats_2[:5]))))\n",
    "        else:\n",
    "            results_df_1, select_feats_1 = plot_top_down_feature_elination_scores(features, random=True)\n",
    "            results_df_2, select_feats_2 = plot_top_down_feature_elination_scores(features, random=True)\n",
    "            print(\"TOP RANDOMIZED REAL FEATURES:\", sorted(list(set(select_feats_1[:5]+select_feats_2[:5]))))\n",
    "        \n",
    "        return sorted(list(set(select_feats_1[:5]+select_feats_2[:5])))\n",
    "\n",
    "            \n",
    "    else:\n",
    "        if noise:\n",
    "            results_df, select_feats = plot_top_down_feature_elination_scores(features, noise=True)\n",
    "            reverse_results_df, reverse_select_feats = plot_top_down_feature_elination_scores(features, reverse=True, noise=True)\n",
    "            print(\"TOP NOISE FEATURES:\", sorted(list(set(select_feats[:5]+reverse_select_feats[:5]))))\n",
    "\n",
    "        else:\n",
    "            results_df, select_feats = plot_top_down_feature_elination_scores(features)\n",
    "            reverse_results_df, reverse_select_feats = plot_top_down_feature_elination_scores(features, reverse=True)\n",
    "            print(\"TOP REAL FEATURES:\", sorted(list(set(select_feats[:5]+reverse_select_feats[:5]))))\n",
    "        \n",
    "        return sorted(list(set(select_feats[:5]+reverse_select_feats[:5])))\n",
    "\n",
    "\n",
    "def rotator_score_df_generator(list_of_feats):\n",
    "\n",
    "    results = {}\n",
    "    removed_feature_list = []\n",
    "    rotater_list = list_of_feats\n",
    "\n",
    "    for i in range(len(list_of_feats)):\n",
    "\n",
    "        removed_feat = rotater_list[-1]\n",
    "        feat_list = rotater_list[:-1]\n",
    "\n",
    "        knc_params = {\n",
    "        'n_neighbors':range(1,50,2)\n",
    "        }\n",
    "\n",
    "        y_train = train_uci_df['target']\n",
    "        X_train = train_uci_df[feat_list]\n",
    "        y_val = val_uci_df['target']\n",
    "        X_val = val_uci_df[feat_list]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "        knc_gs = GridSearchCV(KNeighborsClassifier(), param_grid=knc_params, cv=5, n_jobs=-1)\n",
    "        knc_gs.fit(X_train_scaled, y_train)\n",
    "\n",
    "        train_score = knc_gs.score(X_train_scaled, y_train)\n",
    "        val_score = knc_gs.score(X_val_scaled, y_val)\n",
    "\n",
    "        results[removed_feat] = {'train_score':train_score, 'val_score':val_score, }\n",
    "\n",
    "        rotater_list = [removed_feat] + feat_list\n",
    "\n",
    "    rotater_df = pd.DataFrame(results).T\n",
    "    return rotater_df\n",
    "\n",
    "def removerizer(full_features_list, features_to_remove):\n",
    "    \n",
    "    new_list = full_features_list\n",
    "    \n",
    "    for x in features_to_remove:\n",
    "        new_list.remove(x)\n",
    "\n",
    "    return new_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_20_real_features = sorted([153,442,318,433,241,28,378,475,48,472,451,493,453,281,64,128,105,336,338,455])\n",
    "best_score_list = [28, 48, 105, 128, 153, 281, 318, 336, 338, 378, 442, 451, 455, 472, 475]\n",
    "\n",
    "removeable_feats = list_top_dipped_feats(best_score_list, random=True, noise=True)\n",
    "\n",
    "with_noise_removed_feats = removerizer(best_score_list, removeable_feats)\n",
    "\n",
    "noise_removal_1_df = train_val_scorer_df_maker_KNNC(with_noise_removed_feats, 'noise_removal_1')\n",
    "noise_removal_1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_combos = []\n",
    "for combo in combinations(top_12_real_features, 5):\n",
    "    list_of_combos.append(list(combo))\n",
    "\n",
    "len(list_of_combos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for features in list_of_combos:\n",
    "    \n",
    "    knc_params = {\n",
    "    'n_neighbors':range(3,20,2)\n",
    "    }\n",
    "\n",
    "    y_train = train_uci_df['target']\n",
    "    X_train = train_uci_df[features]\n",
    "    y_val = val_uci_df['target']\n",
    "    X_val = val_uci_df[features]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    knc_gs = GridSearchCV(KNeighborsClassifier(), param_grid=knc_params, cv=5, n_jobs=-1)\n",
    "    knc_gs.fit(X_train_scaled, y_train)\n",
    "\n",
    "    train_score = knc_gs.score(X_train_scaled, y_train)\n",
    "    val_score = knc_gs.score(X_val_scaled, y_val)\n",
    "    \n",
    "    results['{}'.format(features)] = {'train_score':train_score, 'val_score':val_score}\n",
    "    \n",
    "score_df = pd.DataFrame(results).T.sort_values('val_score')\n",
    "\n",
    "score_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_score_list = [28, 48, 105, 128, 153, 281, 318, 336, 338, 378, 442, 451, 455, 472, 475]\n",
    "noise_removal_df = train_val_scorer_df_maker_KNNC(best_score_list, 'noise_removal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_removal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dipped_top_20_feats = list_top_dipped_feats(top_20_real_features)\n",
    "all_dipped_top_20_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "noise_all_dipped_top_20_feats = list_top_dipped_feats(top_20_real_features, noise=True)\n",
    "noise_all_dipped_top_20_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_all_dipped_scores_df = train_val_scorer_df_maker_KNNC(all_dipped_top_20_feats, 'all_dipped_feats')\n",
    "train_val_all_dipped_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_score_df = pd.merge(train_val_scores_df, train_val_all_dipped_scores_df, left_index=True, right_index=True)\n",
    "merged_score_df.T.sort_values('val_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of manual top-down feature elimination\n",
    "\n",
    "The first time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rotater_df = rotator_score_df_generator(top_20_real_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotater_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_to_beat = merged_score_df.T.loc['top_20_real_features']['val_score']\n",
    "score_to_beat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_feats = []\n",
    "\n",
    "for i,x in enumerate(rotater_df['val_score']):\n",
    "    index_list = list(rotater_df.index)\n",
    "    if x <= score_to_beat:\n",
    "        good_feats.append(index_list[i])\n",
    "        \n",
    "good_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_feats_scores_df = train_val_scorer_df_maker_KNNC(good_feats, 'good_feats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_feats_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_14_elasticnet_real_features_scores_df = train_val_scorer_df_maker_KNNC(top_14_elasticnet_real_features, 'top_14_elasticnet_real_features')\n",
    "top_14_elasticnet_real_features_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using GridSearchCV to fit my model with all the training data and using the validation data\n",
    "results = {}\n",
    "all_feat_list_names = ['all_dipped_top_20_feats','top_20_real_features', 'top_12_real_features', 'top_7_real_features', \\\n",
    "                       'top_5_real_features', 'top_14_elasticnet_real_features', 'good_feats']\n",
    "\n",
    "all_feat_lists = [all_dipped_top_20_feats, top_20_real_features, top_12_real_features, top_7_real_features, \\\n",
    "                  top_5_real_features, top_14_elasticnet_real_features, good_feats]\n",
    "\n",
    "\n",
    "for i, feat_list in enumerate(all_feat_lists):\n",
    "\n",
    "    knc_params = {\n",
    "    'n_neighbors':range(1,50,2)\n",
    "    }\n",
    "\n",
    "    y_train = train_uci_df['target']\n",
    "    X_train = train_uci_df[feat_list]\n",
    "    y_val = val_uci_df['target']\n",
    "    X_val = val_uci_df[feat_list]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    knc_gs = GridSearchCV(KNeighborsClassifier(), param_grid=knc_params, cv=5, n_jobs=-1)\n",
    "    knc_gs.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    train_score = knc_gs.score(X_train_scaled, y_train)\n",
    "    val_score = knc_gs.score(X_val_scaled, y_val)\n",
    "    \n",
    "    results[all_feat_list_names[i]] = {'train_score':train_score, 'val_score':val_score, }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores_df = pd.DataFrame(results).T.sort_values('val_score', ascending=False)\n",
    "all_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
