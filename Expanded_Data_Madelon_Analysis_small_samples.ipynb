{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJECT 3: MADELON DATA ANALYSIS\n",
    "\n",
    "Author: William Buck\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install psycopg2 --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run madelon_analyzer.py\n",
    "%run pickle_jar.py\n",
    "%run Expanded_madelon_dataframes_and_features.py\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data - EDA\n",
    "\n",
    "Below is EDA of the expanded Madelon dataset with 1000 features and 200,000 observations. To start with, I've imported 3000 rows and will be performing the same unsupervised learning techniques I used for the smaller UCI dataset to find and remove the noise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this cell, I'm going to try and get a representative sample of the population\n",
    "# https://www.surveymonkey.com/mp/sample-size-calculator/ (confidence level = 90%, margin of error = 1)\n",
    "\n",
    "# con_6506, cur_6506 = con_cur_to_class_db()\n",
    "# cur_6506.execute('SELECT * FROM madelon ORDER BY random() LIMIT 6506')\n",
    "# results_6506 = cur_6506.fetchall()\n",
    "# con_6506.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dataframe of just 6506 samples for initial testing.\n",
    "\n",
    "# samp_6506_bd_df = pd.DataFrame(results_6506)\n",
    "# pd.to_pickle(samp_6506_bd_df, '6506_sample_big_data.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samp_6506_bd_df.index = samp_6506_bd_df['_id']\n",
    "# samp_6506_bd_df = samp_6506_bd_df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dataframe of just 3000 samples for initial testing.\n",
    "\n",
    "# con, cur = con_cur_to_class_db()\n",
    "# %time cur.execute('SELECT * FROM madelon ORDER BY random() LIMIT 3000')\n",
    "# %time results = cur.fetchall()\n",
    "# con.close()\n",
    "\n",
    "# # Dataframe of just 3000 samples for initial testing.\n",
    "\n",
    "# samp_3000_bd_df = pd.DataFrame(results)\n",
    "\n",
    "# pd.to_pickle(samp_3000_bd_df, '3000_sample_big_data.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Columns: 1000 entries, feat_000 to feat_999\n",
      "dtypes: float64(1000)\n",
      "memory usage: 1.5 MB\n"
     ]
    }
   ],
   "source": [
    "X = samp_3000_bd_df.iloc[:200,1:-1]\n",
    "X_2 = samp_3000_bd_df.iloc[200:400,1:-1]\n",
    "X_3 = samp_3000_bd_df.iloc[400:600,1:-1]\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    200.000000\n",
       "mean       0.001668\n",
       "std        1.019437\n",
       "min       -2.800271\n",
       "25%       -0.681074\n",
       "50%        0.001271\n",
       "75%        0.682078\n",
       "max        2.826687\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From this, I can tell that the big uci dataset is already normal\n",
    "X.describe().T.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = samp_3000_bd_df.iloc[:200,-1:]\n",
    "y_2 = samp_3000_bd_df.iloc[200:400,-1:]\n",
    "y_3 = samp_3000_bd_df.iloc[400:600,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making three sample test dataframes\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=42, test_size=0.333)\n",
    "X_2_train, X_2_test, y_2_train, y_2_test = train_test_split(X_2,y_2, random_state=42, test_size=0.333)\n",
    "X_3_train, X_3_test, y_3_train, y_3_test = train_test_split(X_3,y_3, random_state=42, test_size=0.333)\n",
    "\n",
    "train_df = pd.merge(X_train, y_train, left_index=True, right_index=True)\n",
    "train_2_df = pd.merge(X_2_train, y_2_train, left_index=True, right_index=True)\n",
    "train_3_df = pd.merge(X_3_train, y_3_train, left_index=True, right_index=True)\n",
    "\n",
    "test_df = pd.merge(X_test, y_test, left_index=True, right_index=True)\n",
    "test_2_df = pd.merge(X_2_test, y_2_test, left_index=True, right_index=True)\n",
    "test_3_df = pd.merge(X_3_test, y_3_test, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOTE: cell takes 7 minutes to run\n",
    "\n",
    "# ma = madelon_analyzer(train_df, test_df)\n",
    "# ma_2 = madelon_analyzer(train_2_df, test_2_df)\n",
    "# ma_3 = madelon_analyzer(train_3_df, test_3_df)\n",
    "\n",
    "# %time r2_bd_df = ma.mean_r2_for_all_features(train_df, DecisionTreeRegressor)\n",
    "\n",
    "# r2_bd_df = r2_bd_df.sort_values('r2_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2_score</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>0.876759</td>\n",
       "      <td>feat_956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>0.843671</td>\n",
       "      <td>feat_639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>0.601526</td>\n",
       "      <td>feat_315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>0.513198</td>\n",
       "      <td>feat_269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>0.509998</td>\n",
       "      <td>feat_341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>0.483858</td>\n",
       "      <td>feat_724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>0.477938</td>\n",
       "      <td>feat_867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>0.473653</td>\n",
       "      <td>feat_701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0.465809</td>\n",
       "      <td>feat_336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>0.458448</td>\n",
       "      <td>feat_736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.448664</td>\n",
       "      <td>feat_395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>0.43618</td>\n",
       "      <td>feat_769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>0.30044</td>\n",
       "      <td>feat_526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>0.27338</td>\n",
       "      <td>feat_920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.229805</td>\n",
       "      <td>feat_504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>0.220966</td>\n",
       "      <td>feat_681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>0.167354</td>\n",
       "      <td>feat_257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>0.141994</td>\n",
       "      <td>feat_829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>0.121009</td>\n",
       "      <td>feat_308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>-0.242516</td>\n",
       "      <td>feat_808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     r2_score   feature\n",
       "956  0.876759  feat_956\n",
       "639  0.843671  feat_639\n",
       "315  0.601526  feat_315\n",
       "269  0.513198  feat_269\n",
       "341  0.509998  feat_341\n",
       "724  0.483858  feat_724\n",
       "867  0.477938  feat_867\n",
       "701  0.473653  feat_701\n",
       "336  0.465809  feat_336\n",
       "736  0.458448  feat_736\n",
       "395  0.448664  feat_395\n",
       "769   0.43618  feat_769\n",
       "526   0.30044  feat_526\n",
       "920   0.27338  feat_920\n",
       "504  0.229805  feat_504\n",
       "681  0.220966  feat_681\n",
       "257  0.167354  feat_257\n",
       "829  0.141994  feat_829\n",
       "308  0.121009  feat_308\n",
       "808 -0.242516  feat_808"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.to_pickle(r2_bd_df, 'mean_r2_bd_sample_1.p')\n",
    "r2_bd_df = pd.read_pickle('Data/mean_r2_bd_sample_1.p')\n",
    "r2_bd_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2_score</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>0.845707</td>\n",
       "      <td>feat_639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>0.808271</td>\n",
       "      <td>feat_956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>0.575084</td>\n",
       "      <td>feat_315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>0.485985</td>\n",
       "      <td>feat_867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>0.462097</td>\n",
       "      <td>feat_341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>0.417449</td>\n",
       "      <td>feat_701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>0.409274</td>\n",
       "      <td>feat_724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>0.347879</td>\n",
       "      <td>feat_526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>0.327253</td>\n",
       "      <td>feat_769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>0.314855</td>\n",
       "      <td>feat_829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>0.311286</td>\n",
       "      <td>feat_269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0.293929</td>\n",
       "      <td>feat_336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>0.290956</td>\n",
       "      <td>feat_920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.284413</td>\n",
       "      <td>feat_395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>0.279773</td>\n",
       "      <td>feat_257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>0.211217</td>\n",
       "      <td>feat_808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>0.200698</td>\n",
       "      <td>feat_736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.198587</td>\n",
       "      <td>feat_504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>0.188266</td>\n",
       "      <td>feat_681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>0.0590268</td>\n",
       "      <td>feat_308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>-0.5914</td>\n",
       "      <td>feat_859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-0.619932</td>\n",
       "      <td>feat_33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>-0.662935</td>\n",
       "      <td>feat_875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>-0.666162</td>\n",
       "      <td>feat_138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>-0.667927</td>\n",
       "      <td>feat_448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      r2_score   feature\n",
       "639   0.845707  feat_639\n",
       "956   0.808271  feat_956\n",
       "315   0.575084  feat_315\n",
       "867   0.485985  feat_867\n",
       "341   0.462097  feat_341\n",
       "701   0.417449  feat_701\n",
       "724   0.409274  feat_724\n",
       "526   0.347879  feat_526\n",
       "769   0.327253  feat_769\n",
       "829   0.314855  feat_829\n",
       "269   0.311286  feat_269\n",
       "336   0.293929  feat_336\n",
       "920   0.290956  feat_920\n",
       "395   0.284413  feat_395\n",
       "257   0.279773  feat_257\n",
       "808   0.211217  feat_808\n",
       "736   0.200698  feat_736\n",
       "504   0.198587  feat_504\n",
       "681   0.188266  feat_681\n",
       "308  0.0590268  feat_308\n",
       "859    -0.5914  feat_859\n",
       "33   -0.619932   feat_33\n",
       "875  -0.662935  feat_875\n",
       "138  -0.666162  feat_138\n",
       "448  -0.667927  feat_448"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %time r2_bd_2_df = ma_2.mean_r2_for_all_features(train_2_df, DecisionTreeRegressor)\n",
    "# r2_bd_2_df = r2_bd_2_df.sort_values('r2_score', ascending=False)\n",
    "# pd.to_pickle(r2_bd_2_df, 'mean_r2_bd_sample_2.p')\n",
    "r2_bd_2_df = pd.read_pickle('Data/mean_r2_bd_sample_2.p')\n",
    "r2_bd_2_df[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2_score</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>0.806627</td>\n",
       "      <td>feat_639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>0.754375</td>\n",
       "      <td>feat_956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>0.573237</td>\n",
       "      <td>feat_315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>0.519356</td>\n",
       "      <td>feat_724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>0.475584</td>\n",
       "      <td>feat_867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0.472721</td>\n",
       "      <td>feat_336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>0.467021</td>\n",
       "      <td>feat_269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>0.390734</td>\n",
       "      <td>feat_701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>0.375489</td>\n",
       "      <td>feat_920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>0.315068</td>\n",
       "      <td>feat_681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.291377</td>\n",
       "      <td>feat_395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>0.255419</td>\n",
       "      <td>feat_736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>0.250702</td>\n",
       "      <td>feat_257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>0.23143</td>\n",
       "      <td>feat_829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>0.182425</td>\n",
       "      <td>feat_341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>0.176203</td>\n",
       "      <td>feat_769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.172482</td>\n",
       "      <td>feat_504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>0.124137</td>\n",
       "      <td>feat_808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>-0.0130461</td>\n",
       "      <td>feat_308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>-0.329475</td>\n",
       "      <td>feat_526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>-0.564693</td>\n",
       "      <td>feat_824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.661999</td>\n",
       "      <td>feat_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>-0.684159</td>\n",
       "      <td>feat_693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>-0.715089</td>\n",
       "      <td>feat_283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>-0.728706</td>\n",
       "      <td>feat_788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      r2_score   feature\n",
       "639   0.806627  feat_639\n",
       "956   0.754375  feat_956\n",
       "315   0.573237  feat_315\n",
       "724   0.519356  feat_724\n",
       "867   0.475584  feat_867\n",
       "336   0.472721  feat_336\n",
       "269   0.467021  feat_269\n",
       "701   0.390734  feat_701\n",
       "920   0.375489  feat_920\n",
       "681   0.315068  feat_681\n",
       "395   0.291377  feat_395\n",
       "736   0.255419  feat_736\n",
       "257   0.250702  feat_257\n",
       "829    0.23143  feat_829\n",
       "341   0.182425  feat_341\n",
       "769   0.176203  feat_769\n",
       "504   0.172482  feat_504\n",
       "808   0.124137  feat_808\n",
       "308 -0.0130461  feat_308\n",
       "526  -0.329475  feat_526\n",
       "824  -0.564693  feat_824\n",
       "1    -0.661999    feat_1\n",
       "693  -0.684159  feat_693\n",
       "283  -0.715089  feat_283\n",
       "788  -0.728706  feat_788"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %time r2_bd_3_df = ma_3.mean_r2_for_all_features(train_3_df, DecisionTreeRegressor)\n",
    "# r2_bd_3_df = r2_bd_3_df.sort_values('r2_score', ascending=False)\n",
    "# pd.to_pickle(r2_bd_3_df, 'mean_r2_bd_sample_3.p')\n",
    "r2_bd_3_df = pd.read_pickle('Data/mean_r2_bd_sample_3.p')\n",
    "r2_bd_3_df[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First 20 features are all the same for the first 3 samples of the big madelon dataset\n",
    "\n",
    "first_3_bd_samps_correlated_feats_list = \\\n",
    "list(set(list(r2_bd_df[:20].index)+list(r2_bd_2_df[:20].index)+list(r2_bd_3_df[:20].index)))\n",
    "\n",
    "len(set(first_3_bd_samps_correlated_feats_list + feats_extracted_from_10000_samp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_extracted_from_10000_samp = [int(x[5:]) for x in feats_extracted_from_10000_samp_r2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_3_bd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.685500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_score</th>\n",
       "      <td>0.523333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             first_3_bd\n",
       "train_score    0.685500\n",
       "val_score      0.523333"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma_first_3 = madelon_analyzer(samp_3000_bd_df[:2000], samp_3000_bd_df[2000:2600])\n",
    "ma_first_3_benchmark = ma_first_3.train_val_scorer_df_maker(first_3_bd_samps_correlated_feats_list,\\\n",
    "                                                                  'first_3_bd')\n",
    "ma_first_3_benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.19 s, sys: 20 ms, total: 1.21 s\n",
      "Wall time: 2.93 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_3_bd_6506</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.678600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_score</th>\n",
       "      <td>0.518592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             first_3_bd_6506\n",
       "train_score         0.678600\n",
       "val_score           0.518592"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma_first_3_6506 = madelon_analyzer(samp_6506_bd_df[:5000], samp_6506_bd_df[5000:])\n",
    "%time ma_first_3_benchmark_6506 = ma_first_3_6506.train_val_scorer_df_maker(first_3_bd_samps_correlated_feats_list,\\\n",
    "                                                                  'first_3_bd_6506')\n",
    "ma_first_3_benchmark_6506"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ma_6506 = madelon_analyzer(samp_6506_bd_df.iloc[:200,500:], samp_6506_bd_df.iloc[500:600,500:])\n",
    "\n",
    "# %time r2_bd_6506_df = ma_6506.mean_r2_for_all_features(samp_6506_bd_df.iloc[:500,:], DecisionTreeRegressor)\n",
    "\n",
    "# r2_bd_6506_df = r2_bd_6506_df.sort_values('r2_score', ascending=False)\n",
    "\n",
    "# pd.to_pickle(r2_bd_6506_df, 'mean_r2_bd_sample_6506.p')\n",
    "# r2_bd_6506_df = pd.read_pickle('mean_r2_bd_sample_6506.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = samp_6506_bd_df.iloc[:,1:-1]\n",
    "y = samp_6506_bd_df['target']\n",
    "\n",
    "skb_20 = SelectKBest(k=20)\n",
    "skb_20.fit(X, y)\n",
    "skb_20_feats = np.where(skb_20.get_support())[0]\n",
    "skb_20_cols = list(X[skb_20_feats].head().columns)\n",
    "\n",
    "skb_20_cols_new = sorted([int(x[-3:]) for x in skb_20_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_3_bd_samps</th>\n",
       "      <th>skb_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>257</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>269</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>308</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>315</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>336</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>341</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>395</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>504</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>526</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>639</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>681</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>701</td>\n",
       "      <td>724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>724</td>\n",
       "      <td>736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>736</td>\n",
       "      <td>769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>769</td>\n",
       "      <td>808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>808</td>\n",
       "      <td>823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>829</td>\n",
       "      <td>829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>867</td>\n",
       "      <td>849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>920</td>\n",
       "      <td>867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>956</td>\n",
       "      <td>920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    first_3_bd_samps  skb_20\n",
       "0                257     160\n",
       "1                269     257\n",
       "2                308     269\n",
       "3                315     315\n",
       "4                336     336\n",
       "5                341     341\n",
       "6                395     395\n",
       "7                504     490\n",
       "8                526     504\n",
       "9                639     681\n",
       "10               681     701\n",
       "11               701     724\n",
       "12               724     736\n",
       "13               736     769\n",
       "14               769     808\n",
       "15               808     823\n",
       "16               829     829\n",
       "17               867     849\n",
       "18               920     867\n",
       "19               956     920"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([sorted(first_3_bd_samps_correlated_feats_list), skb_20_cols_new], \\\n",
    "             index=['first_3_bd_samps','skb_20']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarks_df = pd.merge(ma_first_3_benchmark, ma_first_3_benchmark_6506, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_3_bd</th>\n",
       "      <th>first_3_bd_6506</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.685500</td>\n",
       "      <td>0.678600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_score</th>\n",
       "      <td>0.523333</td>\n",
       "      <td>0.518592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             first_3_bd  first_3_bd_6506\n",
       "train_score    0.685500         0.678600\n",
       "val_score      0.523333         0.518592"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmarks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skb_20_feats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.67820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_score</th>\n",
       "      <td>0.49668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             skb_20_feats\n",
       "train_score       0.67820\n",
       "val_score         0.49668"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma_skb_6506 = madelon_analyzer(samp_6506_bd_df[:5000], samp_6506_bd_df[5000:])\n",
    "ma_skb_benchmark_6506 = ma_skb_6506.train_val_scorer_df_maker(skb_20_cols_new,\\\n",
    "                                                                  'skb_20_feats')\n",
    "ma_skb_benchmark_6506"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skb_100_feats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.708800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_score</th>\n",
       "      <td>0.552457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             skb_100_feats\n",
       "train_score       0.708800\n",
       "val_score         0.552457"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skb_100 = SelectKBest(k=100)\n",
    "skb_100.fit(X, y)\n",
    "skb_100_feats = np.where(skb_100.get_support())[0]\n",
    "skb_100_cols = list(X[skb_100_feats].head().columns)\n",
    "skb_100_cols_new = sorted([int(x[-3:]) for x in skb_100_cols])\n",
    "ma_skb_100 = madelon_analyzer(samp_6506_bd_df[:5000], samp_6506_bd_df[5000:])\n",
    "ma_skb_100_scores = ma_skb_100.train_val_scorer_df_maker(skb_100_cols_new,\\\n",
    "                                                               'skb_100_feats')\n",
    "ma_skb_100_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sfm_feats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.857000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_score</th>\n",
       "      <td>0.762284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sfm_feats\n",
       "train_score   0.857000\n",
       "val_score     0.762284"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfm = SelectFromModel(LassoCV(), threshold='mean')\n",
    "sfm.fit(X, y)\n",
    "sfm_feats = np.where(sfm.get_support())[0]\n",
    "sfm_cols = list(X[sfm_feats].head().columns)\n",
    "sfm_ma = madelon_analyzer(samp_6506_bd_df[:5000], samp_6506_bd_df[5000:])\n",
    "ma_sfm_scores = sfm_ma.train_val_scorer_df_maker(sfm_cols, 'sfm_feats')\n",
    "ma_sfm_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([269, 681, 701, 808, 829])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfm_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_benchmark_feats = list(set((first_3_bd_samps_correlated_feats_list + skb_20_cols_new)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This shows that all 20 of the columns I selected are included in the top 100 seleced from \n",
    "benchmark_plus_skbtop100 = list(set(all_benchmark_feats + skb_100_cols_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>benchmark_plus_skbtop100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.712200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_score</th>\n",
       "      <td>0.538513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             benchmark_plus_skbtop100\n",
       "train_score                  0.712200\n",
       "val_score                    0.538513"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma_103 = madelon_analyzer(samp_6506_bd_df[:5000], samp_6506_bd_df[5000:])\n",
    "ma_103_scores = ma_103.train_val_scorer_df_maker(benchmark_plus_skbtop100, 'benchmark_plus_skbtop100')\n",
    "ma_103_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# con_103, cur_103 = con_cur_to_class_db()\n",
    "# cur_103.execute(\"SELECT {}, target FROM madelon LIMIT 100000\".format(feats_103))\n",
    "# results_103 = cur_103.fetchall()\n",
    "# con_103.close()\n",
    "# results_103_100000rows_df = pd.DataFrame(results_103)\n",
    "# pd.to_pickle(results_103_100000rows_df, 'Data/results_103_100000rows_df.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_004</th>\n",
       "      <th>feat_010</th>\n",
       "      <th>feat_061</th>\n",
       "      <th>feat_066</th>\n",
       "      <th>feat_078</th>\n",
       "      <th>feat_094</th>\n",
       "      <th>feat_100</th>\n",
       "      <th>feat_104</th>\n",
       "      <th>feat_107</th>\n",
       "      <th>feat_124</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_941</th>\n",
       "      <th>feat_948</th>\n",
       "      <th>feat_954</th>\n",
       "      <th>feat_956</th>\n",
       "      <th>feat_969</th>\n",
       "      <th>feat_970</th>\n",
       "      <th>feat_977</th>\n",
       "      <th>feat_995</th>\n",
       "      <th>feat_996</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.883567</td>\n",
       "      <td>1.684800</td>\n",
       "      <td>0.031787</td>\n",
       "      <td>-0.613555</td>\n",
       "      <td>0.365499</td>\n",
       "      <td>-0.090137</td>\n",
       "      <td>0.645975</td>\n",
       "      <td>0.066871</td>\n",
       "      <td>1.691925</td>\n",
       "      <td>1.868239</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.282699</td>\n",
       "      <td>0.248959</td>\n",
       "      <td>-1.571380</td>\n",
       "      <td>1.072009</td>\n",
       "      <td>1.171244</td>\n",
       "      <td>0.542077</td>\n",
       "      <td>0.375039</td>\n",
       "      <td>-1.363639</td>\n",
       "      <td>-0.737410</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.721962</td>\n",
       "      <td>-0.736924</td>\n",
       "      <td>-0.524250</td>\n",
       "      <td>-1.236556</td>\n",
       "      <td>1.372517</td>\n",
       "      <td>-0.488248</td>\n",
       "      <td>-0.891683</td>\n",
       "      <td>0.197044</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.967551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.598059</td>\n",
       "      <td>1.636510</td>\n",
       "      <td>-1.492728</td>\n",
       "      <td>-3.566485</td>\n",
       "      <td>-0.763321</td>\n",
       "      <td>0.415703</td>\n",
       "      <td>1.027809</td>\n",
       "      <td>1.072134</td>\n",
       "      <td>-0.110998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.090644</td>\n",
       "      <td>0.227951</td>\n",
       "      <td>-0.357068</td>\n",
       "      <td>-1.204669</td>\n",
       "      <td>1.244378</td>\n",
       "      <td>-0.519236</td>\n",
       "      <td>1.668885</td>\n",
       "      <td>-0.830607</td>\n",
       "      <td>-2.515024</td>\n",
       "      <td>-0.450493</td>\n",
       "      <td>...</td>\n",
       "      <td>1.416518</td>\n",
       "      <td>-0.254385</td>\n",
       "      <td>0.833637</td>\n",
       "      <td>-2.919125</td>\n",
       "      <td>-1.831422</td>\n",
       "      <td>-0.237104</td>\n",
       "      <td>0.877890</td>\n",
       "      <td>-0.302300</td>\n",
       "      <td>1.435411</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.137440</td>\n",
       "      <td>0.282772</td>\n",
       "      <td>1.395812</td>\n",
       "      <td>0.548668</td>\n",
       "      <td>0.177660</td>\n",
       "      <td>1.876143</td>\n",
       "      <td>0.157389</td>\n",
       "      <td>0.394322</td>\n",
       "      <td>-0.460903</td>\n",
       "      <td>-0.995456</td>\n",
       "      <td>...</td>\n",
       "      <td>1.412139</td>\n",
       "      <td>-0.446674</td>\n",
       "      <td>-1.388820</td>\n",
       "      <td>0.065801</td>\n",
       "      <td>-1.939555</td>\n",
       "      <td>0.870874</td>\n",
       "      <td>1.629417</td>\n",
       "      <td>-0.057647</td>\n",
       "      <td>-1.176244</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.817359</td>\n",
       "      <td>0.058184</td>\n",
       "      <td>0.595671</td>\n",
       "      <td>0.323599</td>\n",
       "      <td>1.235149</td>\n",
       "      <td>0.774004</td>\n",
       "      <td>0.639562</td>\n",
       "      <td>0.557761</td>\n",
       "      <td>-1.513044</td>\n",
       "      <td>0.280326</td>\n",
       "      <td>...</td>\n",
       "      <td>1.089422</td>\n",
       "      <td>-1.235951</td>\n",
       "      <td>-1.386048</td>\n",
       "      <td>1.349128</td>\n",
       "      <td>-0.379900</td>\n",
       "      <td>-0.875226</td>\n",
       "      <td>0.609906</td>\n",
       "      <td>0.617287</td>\n",
       "      <td>0.691262</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feat_004  feat_010  feat_061  feat_066  feat_078  feat_094  feat_100  \\\n",
       "0 -0.883567  1.684800  0.031787 -0.613555  0.365499 -0.090137  0.645975   \n",
       "1  0.721962 -0.736924 -0.524250 -1.236556  1.372517 -0.488248 -0.891683   \n",
       "2  1.090644  0.227951 -0.357068 -1.204669  1.244378 -0.519236  1.668885   \n",
       "3 -0.137440  0.282772  1.395812  0.548668  0.177660  1.876143  0.157389   \n",
       "4 -0.817359  0.058184  0.595671  0.323599  1.235149  0.774004  0.639562   \n",
       "\n",
       "   feat_104  feat_107  feat_124   ...    feat_941  feat_948  feat_954  \\\n",
       "0  0.066871  1.691925  1.868239   ...   -0.282699  0.248959 -1.571380   \n",
       "1  0.197044 -0.473649 -0.967551   ...    0.598059  1.636510 -1.492728   \n",
       "2 -0.830607 -2.515024 -0.450493   ...    1.416518 -0.254385  0.833637   \n",
       "3  0.394322 -0.460903 -0.995456   ...    1.412139 -0.446674 -1.388820   \n",
       "4  0.557761 -1.513044  0.280326   ...    1.089422 -1.235951 -1.386048   \n",
       "\n",
       "   feat_956  feat_969  feat_970  feat_977  feat_995  feat_996  target  \n",
       "0  1.072009  1.171244  0.542077  0.375039 -1.363639 -0.737410       1  \n",
       "1 -3.566485 -0.763321  0.415703  1.027809  1.072134 -0.110998       1  \n",
       "2 -2.919125 -1.831422 -0.237104  0.877890 -0.302300  1.435411       1  \n",
       "3  0.065801 -1.939555  0.870874  1.629417 -0.057647 -1.176244       1  \n",
       "4  1.349128 -0.379900 -0.875226  0.609906  0.617287  0.691262       1  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_103_100000rows_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:1094: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sfm103_feats_100000rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.766900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_score</th>\n",
       "      <td>0.626667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sfm103_feats_100000rows\n",
       "train_score                 0.766900\n",
       "val_score                   0.626667"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_103 = results_103_100000rows_df.T[:-1].T\n",
    "y_103 = results_103_100000rows_df.T[-1:].T\n",
    "\n",
    "sfm_103 = SelectFromModel(LassoCV(), threshold='mean')\n",
    "sfm_103.fit(X_103, y_103)\n",
    "sfm_103_feats = np.where(sfm_103.get_support())[0]\n",
    "sfm_103_cols = list(X_103.head(1).columns)\n",
    "sfm_103_ma = madelon_analyzer(results_103_100000rows_df[:10000], samp_3000_bd_df)\n",
    "ma_sfm_103_scores = sfm_103_ma.train_val_scorer_df_maker(sfm_103_cols, 'sfm103_feats_100000rows')\n",
    "ma_sfm_103_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sfm2_feats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.699000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_score</th>\n",
       "      <td>0.508632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             sfm2_feats\n",
       "train_score    0.699000\n",
       "val_score      0.508632"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfm2 = SelectFromModel(LassoCV(), threshold='mean')\n",
    "sfm2.fit(X[all_benchmark_feats], y)\n",
    "sfm2_feats = np.where(sfm2.get_support())[0]\n",
    "sfm2_cols = list(X[sfm2_feats].head().columns)\n",
    "sfm2_ma = madelon_analyzer(samp_6506_bd_df[:5000], samp_6506_bd_df[5000:])\n",
    "ma_sfm2_scores = sfm2_ma.train_val_scorer_df_maker(sfm2_cols, 'sfm2_feats')\n",
    "ma_sfm2_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = samp_3000_bd_df.T[1:].T\n",
    "train_df = samp_6506_bd_df.T[1:].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_plus_skbtop100_features = [x for x in pd.read_pickle('Data/results_103_100000rows_df.p').columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run madelon_analyzer\n",
    "\n",
    "RFE = RFE(DecisionTreeClassifier(), n_features_to_select=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFE(estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "  n_features_to_select=20, step=1, verbose=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFE.fit(train_df[benchmark_plus_skbtop100_features], train_df.T[-1:].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFE_feats = np.where(RFE.get_support())[0]\n",
    "RFE_cols = list(train_df[benchmark_plus_skbtop100_features][RFE_feats].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_score</th>\n",
       "      <th>val_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RFE_cols</th>\n",
       "      <td>0.785736</td>\n",
       "      <td>0.736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          train_score  val_score\n",
       "RFE_cols     0.785736      0.736"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma_rfe = madelon_analyzer(train_df, val_df)\n",
    "RFE_cols_score_df = ma_rfe.train_val_scorer_df_maker(RFE_cols, 'RFE_cols', \\\n",
    "                                                     params={'n_neighbors':[1,3,5,7,9,11,13,15,17,19,21]})\n",
    "RFE_cols_score_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 15}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ma_rfe.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # In this cell, I merged all the benchmarks into one dataframe\n",
    "\n",
    "# benchmarks_df = pd.merge(ma_first_3_benchmark, ma_first_3_benchmark_6506, left_index=True, right_index=True)\n",
    "# benchmarks_df = pd.merge(benchmarks_df, ma_skb_benchmark_6506, left_index=True, right_index=True)\n",
    "# benchmarks_df = pd.merge(benchmarks_df, ma_sfm_scores, left_index=True, right_index=True)\n",
    "# benchmarks_df = pd.merge(benchmarks_df, ma_sfm2_scores, left_index=True, right_index=True)\n",
    "# benchmarks_df = pd.merge(benchmarks_df, ma_skb_100_scores, left_index=True, right_index=True)\n",
    "# benchmarks_df = pd.merge(benchmarks_df, ma_103_scores, left_index=True, right_index=True)\n",
    "# multi_benchmarks_df = benchmarks_df.T.sort_values('val_score', ascending=False)\n",
    "# multi_benchmarks_df = pd.merge(multi_benchmarks_df.T, RFE_cols_score_df, left_index=True, right_index=True)\n",
    "# multi_benchmarks_df = multi_benchmarks_df.T.sort_values('val_score', ascending=False)\n",
    "# multi_benchmarks_df['description'] = ['Top 5 using SelectFromModel with LassoCV, threshold=mean',\n",
    "#                                       'Top 20 using RFE',\n",
    "#                                      'Top 100 using SelectKBest', 'SKB top 100 plus top 20',\n",
    "#                                       'Top 20 from the small samples', \n",
    "#                                      'Using the same list from Top 20 from the small samples but on representitive sized sample',\n",
    "#                                      'SFM, on only the top 20 from small samples features', 'SKB top 20']\n",
    "# pd.to_pickle(multi_benchmarks_df, 'Data/multi_benchmarks_df.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(multi_benchmarks_df, 'Data/multi_benchmarks_df.p')\n",
    "multi_benchmarks_df = pd.read_pickle('Data/multi_benchmarks_df.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_benchmarks_df['description'] = ['5 features identified by SFM', '20 features from RFE', \\\n",
    "                                      'SelectKBest top 100', '20 columns identified using regression, plus the skb\\\n",
    "                                      top 100', '20 columns identified using regression tested on 3000 sample',\n",
    "                                     '20 columns identified using regression tested on different 6506 sample',\n",
    "                                     'Used SFM on only the top 20 features identified using regression', 'SKB 20\\\n",
    "                                     features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_score</th>\n",
       "      <th>val_score</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sfm_feats</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.762284</td>\n",
       "      <td>5 features identified by SFM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFE_cols</th>\n",
       "      <td>0.785736</td>\n",
       "      <td>0.736</td>\n",
       "      <td>20 features from RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skb_100_feats</th>\n",
       "      <td>0.7088</td>\n",
       "      <td>0.552457</td>\n",
       "      <td>SelectKBest top 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>benchmark_plus_skbtop100</th>\n",
       "      <td>0.7122</td>\n",
       "      <td>0.538513</td>\n",
       "      <td>20 columns identified using regression, plus t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_3_bd</th>\n",
       "      <td>0.6855</td>\n",
       "      <td>0.523333</td>\n",
       "      <td>20 columns identified using regression tested ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_3_bd_6506</th>\n",
       "      <td>0.6786</td>\n",
       "      <td>0.518592</td>\n",
       "      <td>20 columns identified using regression tested ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sfm2_feats</th>\n",
       "      <td>0.699</td>\n",
       "      <td>0.508632</td>\n",
       "      <td>Used SFM on only the top 20 features identifie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skb_20_feats</th>\n",
       "      <td>0.6782</td>\n",
       "      <td>0.49668</td>\n",
       "      <td>SKB 20                                     fea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         train_score val_score  \\\n",
       "sfm_feats                      0.857  0.762284   \n",
       "RFE_cols                    0.785736     0.736   \n",
       "skb_100_feats                 0.7088  0.552457   \n",
       "benchmark_plus_skbtop100      0.7122  0.538513   \n",
       "first_3_bd                    0.6855  0.523333   \n",
       "first_3_bd_6506               0.6786  0.518592   \n",
       "sfm2_feats                     0.699  0.508632   \n",
       "skb_20_feats                  0.6782   0.49668   \n",
       "\n",
       "                                                                description  \n",
       "sfm_feats                                      5 features identified by SFM  \n",
       "RFE_cols                                               20 features from RFE  \n",
       "skb_100_feats                                           SelectKBest top 100  \n",
       "benchmark_plus_skbtop100  20 columns identified using regression, plus t...  \n",
       "first_3_bd                20 columns identified using regression tested ...  \n",
       "first_3_bd_6506           20 columns identified using regression tested ...  \n",
       "sfm2_feats                Used SFM on only the top 20 features identifie...  \n",
       "skb_20_feats              SKB 20                                     fea...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_benchmarks_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thoughts after benchmarking and initial feature selection\n",
    "\n",
    "Using a naive KNeighborsClassifier, I was able to score a 0.762284 for my validation set. From three random 1% samples of the data, I was able to identify 20 colinear features, which scored 0.518592 when I validated it on a random sample of 6506 rows, which is a representative sample of the population with a 90% confidence level and a 1% margin of error. Since the two clases are balanced, this is not an effective model.\n",
    "\n",
    "Using SelectKBest to get 100 features, I was able to score higher on my validation set than when I looked for 20 features. This tells me that I was probably missing some of the important features in the set of 20 using this method. Although, I descovered that my benchmark list of 20 included 3 features that were not in the SKB top 100 list. So I added them, and will be using all 103 features.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_plus_skbtop100_features = [x for x in pd.read_pickle('Data/results_103_100000rows_df.p').columns[:-1]]\n",
    "benchmark_plus_skbtop100_features.append('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_r2_103_feats = results_103_100000rows_df[benchmark_plus_skbtop100_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_103_100000 = madelon_analyzer(results_103_100000rows_df[:60000], samp_3000_bd_df)\n",
    "\n",
    "bd_103_100000 = ma_103_100000.mean_r2_for_all_features(X_r2_103_feats, DecisionTreeRegressor)\n",
    "bd_103_100000_df = bd_103_100000.sort_values('r2_score', ascending=False)\n",
    "bd_103_100000_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(bd_103_100000_df, 'mean_r2_bd_103_100000_df.p')\n",
    "bd_103_100000_df = pd.read_pickle('Data/mean_r2_bd_103_100000_df.p')\n",
    "bd_103_100000_df[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_score</th>\n",
       "      <th>val_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sfm_feats</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.762284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFE_cols</th>\n",
       "      <td>0.785736</td>\n",
       "      <td>0.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skb_100_feats</th>\n",
       "      <td>0.7088</td>\n",
       "      <td>0.552457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>benchmark_plus_skbtop100</th>\n",
       "      <td>0.7122</td>\n",
       "      <td>0.538513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_3_bd</th>\n",
       "      <td>0.6855</td>\n",
       "      <td>0.523333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_3_bd_6506</th>\n",
       "      <td>0.6786</td>\n",
       "      <td>0.518592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sfm2_feats</th>\n",
       "      <td>0.699</td>\n",
       "      <td>0.508632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skb_20_feats</th>\n",
       "      <td>0.6782</td>\n",
       "      <td>0.49668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         train_score val_score\n",
       "sfm_feats                      0.857  0.762284\n",
       "RFE_cols                    0.785736     0.736\n",
       "skb_100_feats                 0.7088  0.552457\n",
       "benchmark_plus_skbtop100      0.7122  0.538513\n",
       "first_3_bd                    0.6855  0.523333\n",
       "first_3_bd_6506               0.6786  0.518592\n",
       "sfm2_feats                     0.699  0.508632\n",
       "skb_20_feats                  0.6782   0.49668"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_benchmarks_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "\n",
    "Using the madelon_analyzer, I took the top 103 features list and GridSearched a few models including RandomForestClassifier and GradientBoostingClassifier which did improve my model score from benchmark. \n",
    "\n",
    "Using the madelon_analyzer I created, I've been able to score better than benchmark on a couple of occasion. I found that I was able to improve scores by using the ```madelon_analyzer.list_top_dipped_feats(model=KNeighborsClassifier, params='n_neighbors':range(1,20,2), random=True, noise=True)``` method and then repeating the process with a list of features that has the 'noisey' features removed. Below are the graphs that get output, showing the features that were removed marked in blue. By repeating this process several times, I was able to improve my validation score to 0.8185."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 s, sys: 150 ms, total: 10.2 s\n",
      "Wall time: 40.3 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>103 features, RFC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_score</th>\n",
       "      <td>0.755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             103 features, RFC\n",
       "train_score              1.000\n",
       "val_score                0.755"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_params = {\n",
    "    'n_estimators':[10,50,100,200],\n",
    "    'max_features':['auto','log2'],\n",
    "}\n",
    "\n",
    "ma_fi = madelon_analyzer(train_df, val_df)\n",
    "%time ma_fi_scores_103 = ma_fi.train_val_scorer_df_maker(benchmark_plus_skbtop100_features, '103 features, RFC',\\\n",
    "                                                     RandomForestClassifier, rf_params)\n",
    "ma_fi_scores_103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.6 s, sys: 80 ms, total: 12.7 s\n",
      "Wall time: 2min 5s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>103 features, GBC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.932524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_score</th>\n",
       "      <td>0.724667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             103 features, GBC\n",
       "train_score           0.932524\n",
       "val_score             0.724667"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbparams = {\n",
    "    'learning_rate': [0.1,0.5,1], \n",
    "    'n_estimators': [100,200], \n",
    "    'max_depth': [2,4], \n",
    "}\n",
    "\n",
    "ma_gb = madelon_analyzer(train_df, val_df)\n",
    "%time ma_gb_scores_103 = ma_fi.train_val_scorer_df_maker(benchmark_plus_skbtop100_features, '103 features, GBC',\\\n",
    "                                                     GradientBoostingClassifier, gbparams)\n",
    "ma_gb_scores_103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    1511\n",
       "1.0    1489\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_fi = madelon_analyzer(results_103_100000rows_df[:10000], results_103_100000rows_df[10000:12000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_scores_bd_RFE_cols = ma_fi.list_top_dipped_feats(bd_third_best_feats,\\\n",
    "                                            KNeighborsClassifier,\\\n",
    "                                            params={},\\\n",
    "                                            noise=True,\\\n",
    "                                            random=True,\\\n",
    "                                            n_feats_return=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_cols = ma_fi.removerizer(bd_best_feats, fi_scores_bd_RFE_cols)\n",
    "good_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_cols_df = ma_fi.train_val_scorer_df_maker(good_cols, 'with_noise_removal', params={'n_neighbors':range(3,20,2)})\n",
    "good_cols_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>with_noise_removal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.8582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_score</th>\n",
       "      <td>0.8185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             with_noise_removal\n",
       "train_score              0.8582\n",
       "val_score                0.8185"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc_df = ma_fi.train_val_scorer_df_maker(bd_best_feats, 'with_noise_removal', params={'n_neighbors':range(3,20,2)})\n",
    "gc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and Top 5 best score:\n",
    "\n",
    "After reducing the list of features using the madelon_analyzer, I tried every combination of 5 features and found that the best scoring set was ```['feat_681', 'feat_829', 'feat_308', 'feat_724', 'feat_956']```.\n",
    "\n",
    "These Top 5 features when tested with KNN were only marginally better with a validation score of 0.8205. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd_ma_top_scores = madelon_analyzer(results_103_100000rows_df[:10000], results_103_100000rows_df[10000:12000])\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for i, l in enumerate(bd_top_scores_list_of_lists):\n",
    "    if i == 0:\n",
    "        df = bd_ma_top_scores.train_val_scorer_df_maker(l, 'Top 5 Score', \\\n",
    "                                                 params={'n_neighbors':range(1,20,2)})\n",
    "    else:\n",
    "        df = bd_ma_top_scores.train_val_scorer_df_maker(l, 'Number {} score'.format(i), \\\n",
    "                                                 params={'n_neighbors':range(1,20,2)})\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top 5 Score</th>\n",
       "      <th>Number 1 score</th>\n",
       "      <th>Number 2 score</th>\n",
       "      <th>Number 3 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>0.8669</td>\n",
       "      <td>0.8582</td>\n",
       "      <td>0.8414</td>\n",
       "      <td>0.8205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_score</th>\n",
       "      <td>0.8205</td>\n",
       "      <td>0.8185</td>\n",
       "      <td>0.7985</td>\n",
       "      <td>0.7845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Top 5 Score  Number 1 score  Number 2 score  Number 3 score\n",
       "train_score       0.8669          0.8582          0.8414          0.8205\n",
       "val_score         0.8205          0.8185          0.7985          0.7845"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge = pd.merge(dfs[0], dfs[1], left_index=True, right_index=True)\n",
    "df_merge = pd.merge(df_merge, dfs[2], left_index=True, right_index=True)\n",
    "top_scores_df = pd.merge(df_merge, dfs[3], left_index=True, right_index=True)\n",
    "\n",
    "top_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of combinations: 252\n"
     ]
    }
   ],
   "source": [
    "bd_brute_force_combos_df = \\\n",
    "bd_ma_top_scores.brute_force_feature_combination_score_generator(bd_second_best_feats, \\\n",
    "                                                                 model=KNeighborsClassifier,\\\n",
    "                                                                 n_feats=5, \\\n",
    "                                                                 params={'n_neighbors':[3,20,2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_score</th>\n",
       "      <th>val_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>['feat_681', 'feat_829', 'feat_308', 'feat_724', 'feat_956']</th>\n",
       "      <td>0.8897</td>\n",
       "      <td>0.821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['feat_681', 'feat_920', 'feat_724', 'feat_736', 'feat_956']</th>\n",
       "      <td>0.8949</td>\n",
       "      <td>0.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['feat_829', 'feat_701', 'feat_308', 'feat_769', 'feat_808']</th>\n",
       "      <td>0.8945</td>\n",
       "      <td>0.8145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['feat_681', 'feat_920', 'feat_808', 'feat_736', 'feat_956']</th>\n",
       "      <td>0.8289</td>\n",
       "      <td>0.8145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>['feat_920', 'feat_308', 'feat_769', 'feat_808', 'feat_956']</th>\n",
       "      <td>0.8934</td>\n",
       "      <td>0.814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   train_score val_score\n",
       "['feat_681', 'feat_829', 'feat_308', 'feat_724'...      0.8897     0.821\n",
       "['feat_681', 'feat_920', 'feat_724', 'feat_736'...      0.8949     0.815\n",
       "['feat_829', 'feat_701', 'feat_308', 'feat_769'...      0.8945    0.8145\n",
       "['feat_681', 'feat_920', 'feat_808', 'feat_736'...      0.8289    0.8145\n",
       "['feat_920', 'feat_308', 'feat_769', 'feat_808'...      0.8934     0.814"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_brute_force_combos_df.iloc[:,1:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feat_308', 'feat_681', 'feat_724', 'feat_829', 'feat_956']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd_top_5_brute_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top 5 features, RFC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_score</th>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val_score</th>\n",
       "      <td>0.8055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             top 5 features, RFC\n",
       "train_score               1.0000\n",
       "val_score                 0.8055"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_params = {\n",
    "    'n_estimators':[10,50,100,200],\n",
    "    'max_features':['auto','log2'],\n",
    "}\n",
    "\n",
    "bd_ma_five_scores = bd_ma_top_scores.train_val_scorer_df_maker(bd_top_5_brute_f, 'top 5 features, RFC',\\\n",
    "                                                     RandomForestClassifier, rf_params)\n",
    "bd_ma_five_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = results_103_100000rows_df[bd_top_5_brute_f][:10000]\n",
    "X_val = results_103_100000rows_df[bd_top_5_brute_f][10000:13000]\n",
    "y_train = results_103_100000rows_df['target'][:10000]\n",
    "y_val = results_103_100000rows_df['target'][10000:13000]\n",
    "\n",
    "knc_params = {\n",
    "    'n_neighbors':range(3,30,2),\n",
    "    'p':[1,2]\n",
    "    \n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    'criterion':['gini','entropy'],\n",
    "    'max_depth':[None,2,3,4,5,20,100],\n",
    "    \n",
    "}\n",
    "\n",
    "knc_roc = GridSearchCV(KNeighborsClassifier(n_jobs=-1), knc_params)\n",
    "rf_roc = GridSearchCV(RandomForestClassifier(n_jobs=-1), rf_params)\n",
    "\n",
    "rf_roc.fit(X_train, y_train)\n",
    "knc_roc.fit(X_train, y_train)\n",
    "\n",
    "y_preds = knc_roc.predict(X_val)\n",
    "y_proba = knc_roc.predict_proba(X_val)\n",
    "\n",
    "y_preds_rf = rf_roc.predict(X_val)\n",
    "y_proba_rf = rf_roc.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81061276445575925"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_val, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77515532560486866"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_val, y_preds_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'criterion': 'entropy', 'max_depth': None}, {'n_neighbors': 7, 'p': 2})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_roc.best_params_, knc_roc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = results_103_100000rows_df[bd_best_feats][:10000]\n",
    "X_val = results_103_100000rows_df[bd_best_feats][10000:13000]\n",
    "y_train = results_103_100000rows_df['target'][:10000]\n",
    "y_val = results_103_100000rows_df['target'][10000:13000]\n",
    "\n",
    "knc_params = {\n",
    "    'n_neighbors':range(3,30,2),\n",
    "    'p':[1,2]\n",
    "    \n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    'criterion':['gini','entropy'],\n",
    "    'max_depth':[None,2,3,4,5,20,100],\n",
    "    \n",
    "}\n",
    "\n",
    "knc_roc = GridSearchCV(KNeighborsClassifier(n_jobs=-1), knc_params)\n",
    "rf_roc = GridSearchCV(RandomForestClassifier(n_jobs=-1), rf_params)\n",
    "\n",
    "rf_roc.fit(X_train, y_train)\n",
    "knc_roc.fit(X_train, y_train)\n",
    "\n",
    "y_preds = knc_roc.predict(X_val)\n",
    "y_proba = knc_roc.predict_proba(X_val)\n",
    "\n",
    "y_preds_rf = rf_roc.predict(X_val)\n",
    "y_proba_rf = rf_roc.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81193679329016499"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_val, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79497531279570088"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_val, y_preds_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'criterion': 'entropy', 'max_depth': 20}, {'n_neighbors': 7, 'p': 2})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_roc.best_params_, knc_roc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = results_103_100000rows_df.iloc[:10000,:-1]\n",
    "X_val = results_103_100000rows_df.iloc[10000:13000,:-1]\n",
    "y_train = results_103_100000rows_df['target'][:10000]\n",
    "y_val = results_103_100000rows_df['target'][10000:13000]\n",
    "\n",
    "knc_params = {\n",
    "    'n_neighbors':range(3,30,2),\n",
    "    'p':[1,2]\n",
    "    \n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    'criterion':['gini','entropy'],\n",
    "    'max_depth':[None,2,3,4,5,20,100],\n",
    "    \n",
    "}\n",
    "\n",
    "knc_roc = GridSearchCV(KNeighborsClassifier(n_jobs=-1), knc_params)\n",
    "rf_roc = GridSearchCV(RandomForestClassifier(n_jobs=-1), rf_params)\n",
    "\n",
    "rf_roc.fit(X_train, y_train)\n",
    "knc_roc.fit(X_train, y_train)\n",
    "\n",
    "y_preds = knc_roc.predict(X_val)\n",
    "y_proba = knc_roc.predict_proba(X_val)\n",
    "\n",
    "y_preds_rf = rf_roc.predict(X_val)\n",
    "y_proba_rf = rf_roc.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75865518849077151"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_val, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72461200266139136"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_val, y_preds_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'criterion': 'entropy', 'max_depth': None}, {'n_neighbors': 19, 'p': 1})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_roc.best_params_, knc_roc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = results_103_100000rows_df[sfm_cols][:10000]\n",
    "X_val = results_103_100000rows_df[sfm_cols][10000:13000]\n",
    "y_train = results_103_100000rows_df['target'][:10000]\n",
    "y_val = results_103_100000rows_df['target'][10000:13000]\n",
    "\n",
    "knc_params = {\n",
    "    'n_neighbors':range(3,30,2),\n",
    "    'p':[1,2]\n",
    "    \n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    'criterion':['gini','entropy'],\n",
    "    'max_depth':[None,2,3,4,5,20,100],\n",
    "    \n",
    "}\n",
    "\n",
    "knc_roc = GridSearchCV(KNeighborsClassifier(n_jobs=-1), knc_params)\n",
    "rf_roc = GridSearchCV(RandomForestClassifier(n_jobs=-1), rf_params)\n",
    "\n",
    "rf_roc.fit(X_train, y_train)\n",
    "knc_roc.fit(X_train, y_train)\n",
    "\n",
    "y_preds = knc_roc.predict(X_val)\n",
    "y_proba = knc_roc.predict_proba(X_val)\n",
    "\n",
    "y_preds_rf = rf_roc.predict(X_val)\n",
    "y_proba_rf = rf_roc.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.78926963298311836, 0.76202592856466644)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_val, y_preds), roc_auc_score(y_val, y_preds_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'criterion': 'gini', 'max_depth': 20}, {'n_neighbors': 5, 'p': 2})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_roc.best_params_, knc_roc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    " \n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
